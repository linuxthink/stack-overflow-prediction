{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import cPickle as pickle\n",
    "import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# laod raw data\n",
    "start_time = time.time()\n",
    "all_data = pickle.load(open(\"all_data.pickle\", \"rb\"))\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get train and test set\n",
    "train_data = all_data[:900000]\n",
    "valid_data = all_data[900000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre-process 0: build id <-> index infastructure\n",
    "\n",
    "# get all items and users\n",
    "user_ids = sorted(list(set([d['reviewerID'] for d in all_data])))\n",
    "item_ids = sorted(list(set([d['itemID'] for d in all_data])))\n",
    "\n",
    "# build id <-> index map\n",
    "item_id_map_index = dict()\n",
    "item_index_map_id = dict()\n",
    "for index, item_id in enumerate(item_ids):\n",
    "    item_id_map_index[item_id] = index\n",
    "    item_index_map_id[index] = item_id\n",
    "    \n",
    "user_id_map_index = dict()\n",
    "user_index_map_id = dict()\n",
    "for index, user_id in enumerate(user_ids):\n",
    "    user_id_map_index[user_id] = index\n",
    "    user_index_map_id[index] = user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre-process 1: build train_rating_array, valid_rating_array\n",
    "\n",
    "# build array [user_index, item_index, rating]\n",
    "train_rating_array = []\n",
    "for d in train_data:\n",
    "    user_index = user_id_map_index[d['reviewerID']]\n",
    "    item_index = item_id_map_index[d['itemID']]\n",
    "    rating = d['rating']\n",
    "    train_rating_array.append([user_index, item_index, rating])\n",
    "train_rating_array = np.array(train_rating_array).astype(int)\n",
    "\n",
    "# build array [user_index, item_index, rating]\n",
    "valid_rating_array = []\n",
    "for d in valid_data:\n",
    "    user_index = user_id_map_index[d['reviewerID']]\n",
    "    item_index = item_id_map_index[d['itemID']]\n",
    "    rating = d['rating']\n",
    "    valid_rating_array.append([user_index, item_index, rating])\n",
    "valid_rating_array = np.array(valid_rating_array).astype(int)\n",
    "\n",
    "# build array [user_index, item_index, rating]\n",
    "all_rating_array = []\n",
    "for d in all_data:\n",
    "    user_index = user_id_map_index[d['reviewerID']]\n",
    "    item_index = item_id_map_index[d['itemID']]\n",
    "    rating = d['rating']\n",
    "    all_rating_array.append([user_index, item_index, rating])\n",
    "all_rating_array = np.array(all_rating_array).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mse(ratings, ratings_predict):\n",
    "    return np.mean((np.array(ratings).astype('float') - \n",
    "                    np.array(ratings_predict).astype('float')) ** 2.)\n",
    "\n",
    "def get_rmse(ratings, ratings_predict):\n",
    "    return get_mse(ratings, ratings_predict) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_theta(K, num_users, num_items):\n",
    "    alpha = np.mean(train_rating_array[:, 2])\n",
    "    beta_users = np.random.normal(0, 0.5, (num_users, ))\n",
    "    beta_items = np.random.normal(0, 0.5, (num_items, ))\n",
    "    gamma_users = np.random.normal(0, 0.5, (num_users, K))\n",
    "    gamma_items = np.random.normal(0, 0.5, (num_items, K))\n",
    "    \n",
    "    theta_length = (1 + \n",
    "                    beta_users.size + \n",
    "                    beta_items.size +\n",
    "                    gamma_users.size + \n",
    "                    gamma_items.size)\n",
    "    \n",
    "    theta = np.empty((theta_length, ))\n",
    "    return pack(theta, K, alpha, beta_users, beta_items, gamma_users, gamma_items)\n",
    "\n",
    "def pack(theta, K, alpha, beta_users, beta_items, gamma_users, gamma_items):\n",
    "    \"\"\" pack to theta, do not allocate new memory, just copy value\"\"\"\n",
    "    theta[0] = alpha\n",
    "    curr_ind = 1\n",
    "    theta[curr_ind : curr_ind + num_users] = beta_users\n",
    "    curr_ind += num_users\n",
    "    theta[curr_ind : curr_ind + num_items] = beta_items\n",
    "    curr_ind += num_items\n",
    "    theta[curr_ind : curr_ind + num_users * K] = gamma_users.reshape((-1, ))\n",
    "    curr_ind += num_users * K\n",
    "    theta[curr_ind :] = gamma_items.reshape((-1, ))\n",
    "    return theta\n",
    "\n",
    "def unpack(theta, K):\n",
    "    alpha = theta[0]\n",
    "    curr_ind = 1\n",
    "    beta_users = theta[curr_ind : curr_ind + num_users]\n",
    "    curr_ind += num_users\n",
    "    beta_items = theta[curr_ind : curr_ind + num_items]\n",
    "    curr_ind += num_items\n",
    "    gamma_users = theta[curr_ind : curr_ind + num_users * K].reshape((num_users, K))\n",
    "    curr_ind += num_users * K\n",
    "    gamma_items = theta[curr_ind :].reshape((num_items, K))\n",
    "    return (alpha, beta_users, beta_items, gamma_users, gamma_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # sanity check of pack / unpack\n",
    "# # init theta\n",
    "# theta = init_theta(K, num_users, num_items) # all parameters\n",
    "\n",
    "# # check pack and unpack function\n",
    "# a, bu, bi, gu, gi = unpack(theta, K)\n",
    "# theta_new = pack(theta, K, a, bu, bi, gu, gi)\n",
    "# assert np.array_equal(theta, theta_new)\n",
    "\n",
    "# # check value and id sustained\n",
    "# theta[0] = 1234.\n",
    "# (a, bu, bi, gu, gi) = unpack(theta, K)\n",
    "# new_theta = pack(theta, K, a, bu, bi, gu, gi)\n",
    "# assert a == 1234.\n",
    "# assert id(new_theta) == id(theta)\n",
    "# assert new_theta[0] == 1234."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def objective(theta, grad_buffer, rating_array, lam, K):\n",
    "    alpha, beta_users, beta_items, gamma_users, gamma_items = unpack(theta, K)\n",
    "    cost = 0.0\n",
    "    for datum in rating_array:\n",
    "        user_index = datum[0]\n",
    "        item_index = datum[1]\n",
    "        cost += (float(alpha)\n",
    "                 + beta_users[user_index]\n",
    "                 + beta_items[item_index]\n",
    "                 + np.dot(gamma_users[user_index], gamma_items[item_index])\n",
    "                 - float(datum[2])\n",
    "                ) ** 2.0\n",
    "    cost += lam * (np.linalg.norm(theta) ** 2.0)\n",
    "    return 0.5 * cost #/ rating_array.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_user(theta, grad_buffer, rating_array, lam, K):\n",
    "    \"\"\" keep gamma_items_grad to zero \"\"\"\n",
    "    # unpack theta\n",
    "    alpha, beta_users, beta_items, gamma_users, gamma_items = unpack(theta, K)\n",
    "    # reset and unpack grad_buffer\n",
    "    grad_buffer.fill(0.)\n",
    "    alpha_grad, beta_users_grad, beta_items_grad, gamma_users_grad, gamma_items_grad = unpack(grad_buffer, K)\n",
    "    \n",
    "    # cost term: accumulate gradients\n",
    "    for datum in rating_array:\n",
    "        # make prediction\n",
    "        user_index = datum[0]\n",
    "        item_index = datum[1]\n",
    "        prediction = (float(alpha)\n",
    "                      + beta_users[user_index]\n",
    "                      + beta_items[item_index]\n",
    "                      + np.dot(gamma_users[user_index], gamma_items[item_index]))\n",
    "        common_offset = (prediction - float(datum[2])) # offset error\n",
    "        # alpha\n",
    "        alpha_grad += common_offset\n",
    "        # beta_user\n",
    "        beta_users_grad[user_index] += common_offset\n",
    "        # beta_item\n",
    "        beta_items_grad[item_index] += common_offset\n",
    "        # gamma_user\n",
    "        gamma_users_grad[user_index] += common_offset * gamma_items[item_index]\n",
    "        # gamm_item\n",
    "        gamma_items_grad[item_index].fill(0.)\n",
    "    # regularization term\n",
    "    beta_users_grad = beta_users_grad + lam * beta_users\n",
    "    # pack\n",
    "    grad_buffer = pack(grad_buffer, K, alpha_grad, \n",
    "                       beta_users_grad, beta_items_grad, \n",
    "                       gamma_users_grad, gamma_items_grad)\n",
    "    grad_buffer = grad_buffer #/ rating_array.shape[0]\n",
    "    return grad_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_item(theta, grad_buffer, rating_array, lam, K):\n",
    "    \"\"\" keep gamma_users_grad to zero \"\"\"\n",
    "    # unpack theta\n",
    "    alpha, beta_users, beta_items, gamma_users, gamma_items = unpack(theta, K)\n",
    "    # reset and unpack grad_buffer\n",
    "    grad_buffer.fill(0.)\n",
    "    alpha_grad, beta_users_grad, beta_items_grad, gamma_users_grad, gamma_items_grad = unpack(grad_buffer, K)\n",
    "    \n",
    "    # cost term: accumulate gradients\n",
    "    for datum in rating_array:\n",
    "        # make prediction\n",
    "        user_index = datum[0]\n",
    "        item_index = datum[1]\n",
    "        prediction = (float(alpha)\n",
    "                      + beta_users[user_index]\n",
    "                      + beta_items[item_index]\n",
    "                      + np.dot(gamma_users[user_index], gamma_items[item_index]))\n",
    "        common_offset = (prediction - float(datum[2])) # offset error\n",
    "        # alpha\n",
    "        alpha_grad += common_offset\n",
    "        # beta_user\n",
    "        beta_users_grad[user_index] += common_offset\n",
    "        # beta_item\n",
    "        beta_items_grad[item_index] += common_offset\n",
    "        # gamma_user\n",
    "        gamma_users_grad[user_index].fill(0.)\n",
    "        # gamm_item\n",
    "        gamma_items_grad[item_index] += common_offset * gamma_users[user_index]\n",
    "    # regularization term\n",
    "    beta_items_grad = beta_items_grad + lam * beta_items\n",
    "    \n",
    "    # pack\n",
    "    grad_buffer = pack(grad_buffer, K, alpha_grad, \n",
    "                       beta_users_grad, beta_items_grad, \n",
    "                       gamma_users_grad, gamma_items_grad)\n",
    "    grad_buffer = grad_buffer #/ rating_array.shape[0]\n",
    "    return grad_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_one_rating(user_index, item_index, theta, K):\n",
    "    user_index = int(user_index)\n",
    "    item_index = int(item_index)\n",
    "    alpha, beta_users, beta_items, gamma_users, gamma_items = unpack(theta, K)\n",
    "    \n",
    "    # user\n",
    "    beta_user = beta_users[user_index]\n",
    "    gamma_user = gamma_users[user_index]\n",
    "    \n",
    "    # item\n",
    "    beta_item = beta_items[item_index]\n",
    "    gamma_item = gamma_items[item_index]\n",
    "    \n",
    "    return alpha + beta_user + beta_item + np.dot(gamma_user, gamma_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_and_get_rmse(data, theta, K):\n",
    "    ratings_predict = [predict_one_rating(user_index, item_index, theta, K) \n",
    "                       for user_index, item_index in data[:, :2]]\n",
    "    ratings = data[:, 2]\n",
    "    return get_rmse(ratings_predict, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def progress_callback(theta):\n",
    "    print(\"train rmse:\", test_and_get_rmse(train_rating_array, theta, K))\n",
    "    print(\"valid rmse:\", test_and_get_rmse(valid_rating_array, theta, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# global variableds\n",
    "K = 10\n",
    "lam = 1.0\n",
    "num_users = len(user_ids)\n",
    "num_items = len(item_ids)\n",
    "\n",
    "# init theta and grad_buffer\n",
    "theta = init_theta(K, num_users, num_items)\n",
    "grad_buffer = np.zeros_like(theta)\n",
    "\n",
    "res = minimize(objective, \n",
    "               theta, \n",
    "               method='L-BFGS-B',\n",
    "               jac=gradient_user, \n",
    "               options={'disp': True, 'maxiter': 20},\n",
    "               callback=progress_callback,\n",
    "               args = (grad_buffer, train_rating_array, lam, K))\n",
    "theta = res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = minimize(objective, \n",
    "               theta, \n",
    "               method='L-BFGS-B',\n",
    "               jac=gradient_item, \n",
    "               options={'disp': True, 'maxiter': 20},\n",
    "               callback=progress_callback,\n",
    "               args = (grad_buffer, train_rating_array, lam, K))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
