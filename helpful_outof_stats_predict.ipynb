{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# idea:\n",
    "# - every user, every item, and global have an average\n",
    "# - after averaging statistics, these average is fixe|d\n",
    "# - fit regression model to fit this average to the original training data to get coefficient\n",
    "# - thus must be better than the provided baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import cPickle as pickle\n",
    "import time\n",
    "import os\n",
    "\n",
    "data_root = os.path.expanduser(\"~\") + '/data/CSE255/'\n",
    "\n",
    "import cvxopt as co\n",
    "from l1 import l1\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.086466074\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "all_data = pickle.load(open(data_root + \"all_data.pickle\", \"rb\"))\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_size = len(all_data)\n",
    "train_size = 900000\n",
    "# train_size = all_size # uncomment this to produce test\n",
    "valid_size = 100000\n",
    "train_data = all_data[:train_size]\n",
    "valid_data = all_data[all_size - valid_size:]\n",
    "\n",
    "# remove the outlier\n",
    "for i in reversed(range(train_size)):\n",
    "    if train_data[i]['helpful']['outOf'] > 4500:\n",
    "        train_data.pop(i)\n",
    "\n",
    "for i in reversed(range(valid_size)):\n",
    "    if valid_data[i]['helpful']['outOf'] > 4500:\n",
    "        valid_data.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def get_mae(helpfuls, helpfuls_predict):\n",
    "    return np.sum(np.fabs(helpfuls_predict - helpfuls.astype(float))) / helpfuls.shape[0]\n",
    "\n",
    "def get_valid_mae(valid_data, train_ratio_list):\n",
    "    helpfuls = np.array([float(d['helpful']['nHelpful']) for d in valid_data])\n",
    "    helpfuls_predict = np.array([predict_helpful(d, train_ratio_list) for d in valid_data])\n",
    "    return get_mae(helpfuls, helpfuls_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gather statistics about every outofs\n",
    "train_helpfuls = np.array([d['helpful']['nHelpful'] for d in train_data])\n",
    "train_outofs =  np.array([d['helpful']['outOf'] for d in train_data])\n",
    "\n",
    "train_unique_outofs = np.array(sorted(list(set(train_outofs))))\n",
    "train_unique_outofs_mean_helpfuls = np.array([np.mean(train_helpfuls[train_outofs == o]) \n",
    "                                              for o in train_unique_outofs])\n",
    "train_unique_outofs_ratio = train_unique_outofs_mean_helpfuls[1:] / train_unique_outofs[1:]\n",
    "train_unique_outofs_ratio = np.array([0.] + list(train_unique_outofs_ratio))\n",
    "# plt.plot(train_unique_outofs, train_unique_outofs_ratio)\n",
    "# plt.plot(train_unique_outofs[:600], train_unique_outofs_ratio[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal helpfulness ratio 0.8811\n"
     ]
    }
   ],
   "source": [
    "# build a train ratio dict\n",
    "\n",
    "# set cut of, anything larger than cutof use global\n",
    "cut_off = 20\n",
    "train_unique_outofs = list(train_unique_outofs)\n",
    "train_unique_outofs_ratio = list(train_unique_outofs_ratio)\n",
    "\n",
    "def linear_search_ratio(helpfuls, outofs, search_range=(0.3, 1.0, 0.001)):\n",
    "    alphas = np.arange(*search_range)\n",
    "    errors = [get_mae(helpfuls, outofs * alpha) for alpha in alphas]\n",
    "    optimal_alpha = alphas[np.argmin(errors)]\n",
    "    return optimal_alpha\n",
    "\n",
    "# training set global\n",
    "train_avg_ratio = linear_search_ratio(train_helpfuls[train_outofs > cut_off],\n",
    "                                      train_outofs[train_outofs > cut_off], \n",
    "                                      search_range=(0.3, 1.0, 0.0001))\n",
    "print('optimal helpfulness ratio', train_avg_ratio)\n",
    "\n",
    "\n",
    "train_ratio_list = [0.0] * 6000\n",
    "for i in range(6000):\n",
    "    if i <= cut_off:\n",
    "        train_ratio_list[i] = train_unique_outofs_ratio[train_unique_outofs.index(i)]\n",
    "    else:\n",
    "        train_ratio_list[i] = train_avg_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_helpful(d, train_ratio_list):\n",
    "    outof = float(d['helpful']['outOf'])\n",
    "    ratio = train_ratio_list[int(outof)]\n",
    "    return ratio * outof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.648657128046\n"
     ]
    }
   ],
   "source": [
    "print(get_valid_mae(valid_data, train_ratio_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('train_ratio_list.pickle', 'w') as f:\n",
    "    pickle.dump(train_ratio_list, f)\n",
    "    \n",
    "with open('train_ratio_list.pickle') as f:\n",
    "    train_ratio_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ############ produce test ############\n",
    "\n",
    "# # load helpful_data.json\n",
    "# test_data = pickle.load(open(data_root + \"helpful_data.pickle\", \"rb\"))\n",
    "\n",
    "# # on test set\n",
    "# test_helpfuls_predict = [predict_helpful(d, theta, train_avg_ratio, users_ratio, items_ratio) for d in test_data]\n",
    "\n",
    "# # load 'pairs_Helpful.txt'\n",
    "# # get header_str and user_item_outofs\n",
    "# with open('pairs_Helpful.txt') as f:\n",
    "#     # read and strip lines\n",
    "#     lines = [l.strip() for l in f.readlines()]\n",
    "#     # stirip out the headers\n",
    "#     header_str = lines.pop(0)\n",
    "#     # get a list of user_item_ids\n",
    "#     user_item_outofs = [l.split('-') for l in lines]\n",
    "#     user_item_outofs = [[d[0], d[1], float(d[2])] for d in user_item_outofs]\n",
    "    \n",
    "# # make sure `data.json` and `pairs_Helpful.txt` the same order\n",
    "# for (user_id, item_id, outof), d in zip(user_item_outofs, test_data):\n",
    "#     assert d['reviewerID'] == user_id\n",
    "#     assert d['itemID'] == item_id\n",
    "#     assert d['helpful']['outOf'] == outof\n",
    "    \n",
    "# # write to output file\n",
    "# f = open('predictions_Helpful.txt', 'w')\n",
    "# print(header_str, file=f)\n",
    "# for (user_id, item_id, outof), test_helpful_predict in zip(user_item_outofs, test_helpfuls_predict):\n",
    "#     print('%s-%s-%s,%s' % (user_id, item_id, int(outof), test_helpful_predict), file=f)\n",
    "# f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
