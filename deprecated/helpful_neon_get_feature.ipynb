{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 128 \n",
      "vocab_size: 20000 \n",
      "sentence_length: 100 \n",
      "embedding_dim: 128 \n",
      "hidden_size: 128\n"
     ]
    }
   ],
   "source": [
    "from neon.backends import gen_backend\n",
    "from neon.data import DataIterator, Text, load_text\n",
    "from neon.initializers import Uniform, GlorotUniform\n",
    "from neon.layers import GeneralizedCost, LSTM, Affine, Dropout, LookupTable, RecurrentSum\n",
    "from neon.models import Model\n",
    "from neon.optimizers import Adagrad\n",
    "from neon.transforms import Rectlin, Logistic, Tanh, Softmax, CrossEntropyMulti, Accuracy\n",
    "from neon.callbacks.callbacks import Callbacks\n",
    "from neon.util.argparser import NeonArgparser\n",
    "import numpy as np\n",
    "import os\n",
    "import cPickle as pickle\n",
    "data_root = os.path.expanduser(\"~\") + '/data/CSE255/'\n",
    "\n",
    "class Args():\n",
    "    pass\n",
    "args = Args()\n",
    "\n",
    "# the command line arguments\n",
    "args.backend = 'gpu'\n",
    "args.batch_size = 128\n",
    "args.epochs = 3\n",
    "\n",
    "args.config = None\n",
    "args.data_dir = '/home/linuxthink/nervana/data'\n",
    "args.datatype = np.float32\n",
    "args.device_id = 0\n",
    "args.evaluation_freq = 1\n",
    "args.history = 1\n",
    "args.log_thresh = 40\n",
    "args.logfile = None\n",
    "args.model_file = None\n",
    "args.no_progress_bar = False\n",
    "args.output_file = '/home/linuxthink/nervana/data/neonlog.hd5'\n",
    "args.progress_bar = True\n",
    "args.rng_seed = 0\n",
    "args.rounding = False\n",
    "args.save_path = '/home/linuxthink/nervana/data/128128_49_model'\n",
    "args.serialize = 1\n",
    "args.verbose = 1\n",
    "\n",
    "num_epochs = args.epochs\n",
    "\n",
    "# hyperparameters from the reference\n",
    "batch_size = 128\n",
    "clip_gradients = True\n",
    "gradient_limit = 15\n",
    "vocab_size = 20000\n",
    "sentence_length = 100\n",
    "embedding_dim = 128\n",
    "hidden_size = 128\n",
    "reset_cells = True\n",
    "\n",
    "print('batch_size: %s \\nvocab_size: %s \\nsentence_length: %s \\nembedding_dim: %s \\nhidden_size: %s' %\n",
    "      (batch_size,      vocab_size,      sentence_length,      embedding_dim,      hidden_size))\n",
    "\n",
    "# setup backend\n",
    "be = gen_backend(backend=args.backend,\n",
    "                 batch_size=batch_size,\n",
    "                 rng_seed=args.rng_seed,\n",
    "                 device_id=args.device_id,\n",
    "                 default_dtype=args.datatype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# my own view at the pickle file\n",
    "# a = pickle.load(open(os.path.join(data_root, 'train_valid_text_index_in_binary_label.pickle'), \"rb\"))\n",
    "# pickle.dump(a, open(os.path.join(data_root, 'train_valid_text_index_in_binary_label.pickle'), \"wb\"),\n",
    "#             protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of train sentences 1000000\n"
     ]
    }
   ],
   "source": [
    "# load train set\n",
    "(X_train, y_train) = Text.pad_data(os.path.join(data_root, 'train_valid_text_index_in_binary_label_complete.pickle'),\n",
    "                                   vocab_size=vocab_size, \n",
    "                                   sentence_length=sentence_length,\n",
    "                                   test_split=0.0)\n",
    "print \"# of train sentences\", X_train.shape[0]\n",
    "\n",
    "# make train_set (for the callbacks)\n",
    "train_set = DataIterator(X_train, y_train, nclass=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = Text.pad_data(os.path.join(data_root, 'test_text_index.pickle'),\n",
    "                       vocab_size=vocab_size, \n",
    "                       sentence_length=sentence_length,\n",
    "                       test_split=0.0,\n",
    "                       feature_only=True)\n",
    "y_test = np.zeros((X_test.shape[0], 1))\n",
    "test_set = DataIterator(X_test, y_test, nclass=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neon.callbacks.callbacks:Overwriting output file /home/linuxthink/nervana/data/neonlog.hd5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<neon.layers.layer.LookupTable object at 0x7fec640dec90>, <neon.layers.recurrent.LSTM object at 0x7fec5e486250>, <neon.layers.recurrent.RecurrentSum object at 0x7fec5e486290>, <neon.layers.layer.Dropout object at 0x7fec5e4863d0>, [<neon.layers.layer.Linear object at 0x7fec5e4864d0>, <neon.layers.layer.Bias object at 0x7fec5e486410>, <neon.layers.layer.Activation object at 0x7fec5e486650>]]\n"
     ]
    }
   ],
   "source": [
    "# weight initialization\n",
    "init_emb = Uniform(low=-0.1 / embedding_dim, high=0.1 / embedding_dim)\n",
    "init_glorot = GlorotUniform()\n",
    "\n",
    "layers = [\n",
    "    LookupTable(\n",
    "        vocab_size=vocab_size, embedding_dim=embedding_dim, init=init_emb),\n",
    "    LSTM(hidden_size, init_glorot, activation=Tanh(),\n",
    "         gate_activation=Logistic(), reset_cells=True),\n",
    "    RecurrentSum(),\n",
    "    Dropout(keep=0.5),\n",
    "    Affine(2, init_glorot, bias=init_glorot, activation=Softmax())\n",
    "]\n",
    "\n",
    "print(layers)\n",
    "\n",
    "cost = GeneralizedCost(costfunc=CrossEntropyMulti(usebits=True))\n",
    "metric = Accuracy()\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "model = Model(layers=layers)\n",
    "optimizer = Adagrad(learning_rate=0.01, clip_gradients=clip_gradients)\n",
    "callbacks = Callbacks(model, train_set, args, eval_set=train_set)\n",
    "\n",
    "model.load_weights(os.path.join(args.data_dir, '128128_49_model_e0.pkl'))\n",
    "\n",
    "model.initialized = False\n",
    "model.initialize(train_set, cost=cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output result\n",
    "test_ratio_predicitons = []\n",
    "for x, _ in test_set:\n",
    "    x = model.fprop(x, inference=True)\n",
    "    test_ratio_predicitons += list(x.get()[1])\n",
    "test_ratio_predicitons = test_ratio_predicitons[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output result\n",
    "all_ratio_predicitons = []\n",
    "for x, _ in train_set:\n",
    "    x = model.fprop(x, inference=True)\n",
    "    all_ratio_predicitons += list(x.get()[1])\n",
    "all_ratio_predicitons = all_ratio_predicitons[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 50000)\n"
     ]
    }
   ],
   "source": [
    "print(len(all_ratio_predicitons), len(test_ratio_predicitons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump((all_ratio_predicitons, test_ratio_predicitons), \n",
    "            open(\"all_ratio_predict_test_ratio_predict.pickle\", \"wb\"), \n",
    "            protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
