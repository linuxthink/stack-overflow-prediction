{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# my version of the algorithm used in the baseline\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import cPickle as pickle\n",
    "import time\n",
    "import os\n",
    "from __future__ import print_function\n",
    "\n",
    "data_root = os.path.expanduser(\"~\") + '/data/CSE255/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.8276500702\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "all_data = pickle.load(open(data_root + \"all_data.pickle\", \"rb\"))\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_size = len(all_data)\n",
    "train_size = 900000\n",
    "# train_size = all_size\n",
    "valid_size = 100000\n",
    "train_data = all_data[:train_size]\n",
    "valid_data = all_data[all_size - valid_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def get_mae(helpfuls, helpfuls_predict):\n",
    "    return np.sum(np.fabs(helpfuls_predict - helpfuls.astype(float))) / helpfuls.shape[0]\n",
    "\n",
    "def get_valid_mae(valid_data, alpha, beta_us, beta_is):\n",
    "    helpfuls = np.array([float(d['helpful']['nHelpful']) for d in valid_data])\n",
    "    helpfuls_predict = np.array([predict_helpful(d, alpha, beta_us, beta_is) for d in valid_data])\n",
    "    return get_mae(helpfuls, helpfuls_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pre-process 0: build id <-> index infastructure\n",
    "\n",
    "# get all items and users\n",
    "item_ids = sorted(list(set([d['itemID'] for d in all_data])))\n",
    "user_ids = sorted(list(set([d['reviewerID'] for d in all_data])))\n",
    "\n",
    "# user and item numbers\n",
    "num_items = len(item_ids)\n",
    "num_users = len(user_ids)\n",
    "\n",
    "# build id <-> index map\n",
    "item_id_map_index = dict()\n",
    "item_index_map_id = dict()\n",
    "for index, item_id in enumerate(item_ids):\n",
    "    item_id_map_index[item_id] = index\n",
    "    item_index_map_id[index] = item_id\n",
    "    \n",
    "user_id_map_index = dict()\n",
    "user_index_map_id = dict()\n",
    "for index, user_id in enumerate(user_ids):\n",
    "    user_id_map_index[user_id] = index\n",
    "    user_index_map_id[index] = user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre-process 1: build train_ratio_array, valid_ratio_array\n",
    "\n",
    "def get_ratio(d):\n",
    "    return float(d['helpful']['nHelpful']) / float(d['helpful']['outOf'])\n",
    "\n",
    "# build array [user_index, item_index, ratio]\n",
    "train_ratio_array = []\n",
    "for d in train_data:\n",
    "    user_index = user_id_map_index[d['reviewerID']]\n",
    "    item_index = item_id_map_index[d['itemID']]\n",
    "    if float(d['helpful']['outOf']) != 0:\n",
    "        ratio = get_ratio(d)\n",
    "        train_ratio_array.append([user_index, item_index, ratio])\n",
    "train_ratio_array = np.array(train_ratio_array)\n",
    "\n",
    "# build array [user_index, item_index, ratio]\n",
    "valid_ratio_array = []\n",
    "for d in valid_data:\n",
    "    user_index = user_id_map_index[d['reviewerID']]\n",
    "    item_index = item_id_map_index[d['itemID']]\n",
    "    if float(d['helpful']['outOf']) != 0:\n",
    "        ratio = get_ratio(d)\n",
    "        valid_ratio_array.append([user_index, item_index, ratio])\n",
    "valid_ratio_array = np.array(valid_ratio_array)\n",
    "\n",
    "# build array [user_index, item_index, ratio]\n",
    "all_ratio_array = []\n",
    "for d in all_data:\n",
    "    user_index = user_id_map_index[d['reviewerID']]\n",
    "    item_index = item_id_map_index[d['itemID']]\n",
    "    if float(d['helpful']['outOf']) != 0:\n",
    "        ratio = get_ratio(d)\n",
    "        all_ratio_array.append([user_index, item_index, ratio])\n",
    "all_ratio_array = np.array(all_ratio_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility and update functions\n",
    "\n",
    "def get_valid_mse(lam, alpha, beta_us, beta_is, ratio_array, valid_ratio_array):\n",
    "    predicts = alpha + beta_us[valid_ratio_array[:, 0].astype(int)] + beta_is[valid_ratio_array[:, 1].astype(int)]\n",
    "    ratios = valid_ratio_array[:, 2].astype(float)\n",
    "    return (1. / valid_ratio_array.shape[0]) * np.sum((predicts - ratios) ** 2.0)\n",
    "\n",
    "def get_cost(lam, alpha, beta_us, beta_is, train_ratio_array, Ruis, Rius):\n",
    "    predicts = alpha + beta_us[train_ratio_array[:, 0].astype(int)] + beta_is[train_ratio_array[:, 1].astype(int)]\n",
    "    ratios = train_ratio_array[:, 2].astype(float)\n",
    "    return np.sum((predicts - ratios) ** 2.) + lam * (np.sum(beta_us ** 2.) + np.sum(beta_is ** 2.))\n",
    "\n",
    "def alpha_update(lam, alpha, beta_us, beta_is, train_ratio_array, Ruis, Rius):\n",
    "    sum_Rui = np.sum(train_ratio_array[:, 2])\n",
    "    sum_beta_u = np.sum(beta_us[train_ratio_array[:, 0].astype(int)]) # fancy indexing\n",
    "    sum_beta_i = np.sum(beta_is[train_ratio_array[:, 1].astype(int)]) # fancy indexing\n",
    "    return (sum_Rui - sum_beta_u - sum_beta_i) / train_ratio_array.shape[0]\n",
    "\n",
    "def beta_us_update(lam, alpha, beta_us, beta_is, train_ratio_array, Ruis, Rius):\n",
    "    new_beta_us = np.zeros_like(beta_us)\n",
    "    for user_index in xrange(num_users):\n",
    "        # [the set of items] reviewed by user u\n",
    "        Iu = Ruis[user_index].keys()\n",
    "        Iu_size = len(Iu)\n",
    "        # sums\n",
    "        sum_Rui = np.sum(Ruis[user_index].values())\n",
    "        sum_alpha = Iu_size * alpha\n",
    "        sum_beta_i = np.sum(beta_is[Iu])\n",
    "        # write result\n",
    "        new_beta_us[user_index] = float(sum_Rui - sum_alpha - sum_beta_i) / (lam + Iu_size)\n",
    "    return new_beta_us\n",
    "\n",
    "def beta_is_update(lam, alpha, beta_us, beta_is, train_ratio_array, Ruis, Rius):\n",
    "    new_beta_is = np.zeros_like(beta_is)\n",
    "    for item_index in xrange(num_items):\n",
    "        # [the set of users] reviewd item i\n",
    "        Ui = Rius[item_index].keys()\n",
    "        Ui_size = len(Ui)\n",
    "        # sums\n",
    "        sum_Rui = np.sum(Rius[item_index].values())\n",
    "        sum_alpha = Ui_size * alpha\n",
    "        sum_beta_u = np.sum(beta_us[Ui])\n",
    "        # write result\n",
    "        new_beta_is[item_index] = float(sum_Rui - sum_alpha - sum_beta_u) / (lam + Ui_size)\n",
    "    return new_beta_is\n",
    "\n",
    "def train_and_eval(max_iter,\n",
    "                   lam, alpha, beta_us, beta_is,\n",
    "                   train_ratio_array, valid_ratio_array, valid_data,\n",
    "                   print_step = False):\n",
    "    # print init valid mae\n",
    "    print('init valid mae', get_valid_mae(valid_data, alpha, beta_us, beta_is))\n",
    "\n",
    "    # build Mapping of Ruis and Rius\n",
    "    Ruis = defaultdict(dict)\n",
    "    Rius = defaultdict(dict)\n",
    "\n",
    "    # Notes:\n",
    "    # Iu = Ruis[user_index].keys() # [the set of items] reviewed by user u\n",
    "    # Ui = Ruis[item_index].keys() # [the set of users] reviewed item i\n",
    "\n",
    "    for t in train_ratio_array:\n",
    "        user_index = t[0]\n",
    "        item_index = t[1]\n",
    "        ratio = t[2]\n",
    "        Ruis[user_index][item_index] = ratio\n",
    "        Rius[item_index][user_index] = ratio\n",
    "\n",
    "    # train on this dataset\n",
    "    for i in xrange(max_iter):\n",
    "        alpha = alpha_update(lam, alpha, beta_us, beta_is, train_ratio_array, Ruis, Rius)\n",
    "        # print('alpha valid mae', get_valid_mae(valid_data, alpha, beta_us, beta_is))\n",
    "        beta_us = beta_us_update(lam, alpha, beta_us, beta_is, train_ratio_array, Ruis, Rius)\n",
    "        # print('beta_us valid mae', get_valid_mae(valid_data, alpha, beta_us, beta_is))\n",
    "        beta_is = beta_is_update(lam, alpha, beta_us, beta_is, train_ratio_array, Ruis, Rius)\n",
    "        # print('beta_is valid mae', get_valid_mae(valid_data, alpha, beta_us, beta_is))\n",
    "        if print_step:\n",
    "            cost = get_cost(lam, alpha, beta_us, beta_is, train_ratio_array, Ruis, Rius)\n",
    "            valid_mse = get_valid_mse(lam, alpha, beta_us, beta_is,\n",
    "                                      train_ratio_array, valid_ratio_array)\n",
    "            valid_mae = get_valid_mae(valid_data, alpha, beta_us, beta_is)\n",
    "            print(i, alpha, np.mean(beta_us), np.mean(beta_is), cost, valid_mse, valid_mae)\n",
    "\n",
    "    cost = get_cost(lam, alpha, beta_us, beta_is, train_ratio_array, Ruis, Rius)\n",
    "    valid_mse = get_valid_mse(lam, alpha, beta_us, beta_is, train_ratio_array, valid_ratio_array)\n",
    "\n",
    "    return(cost, valid_mse, alpha, beta_us, beta_is)\n",
    "\n",
    "def predict_helpful(d, alpha, beta_us, beta_is):\n",
    "    user_id = d['reviewerID']\n",
    "    item_id = d['itemID']\n",
    "    outof = float(d['helpful']['outOf'])\n",
    "    ratio = alpha + beta_us[user_id_map_index[user_id]] + beta_is[item_id_map_index[item_id]]\n",
    "    ratio = min(5.0, ratio)\n",
    "    ratio = max(0.0, ratio)\n",
    "    helpful_predict = ratio * outof\n",
    "    \n",
    "    return helpful_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init valid mae 2.06413040563\n",
      "0 0.740383654039 -0.00567808551813 0.0066395307487 41682.5936359 0.111053196786 0.76313378734\n",
      "1 0.740910472175 -0.00530682178558 0.00724577690491 34535.2181975 0.0938087967428 0.684868892803\n",
      "2 0.741485393331 -0.00638568394396 0.0069361522775 34353.71376 0.0933739509632 0.682143401704\n",
      "3 0.742035747107 -0.00717262321597 0.00633296835429 34327.5361108 0.0933128021412 0.681174642781\n",
      "4 0.74253824084 -0.00762514103837 0.0056200893355 34315.9202088 0.0932845801619 0.680503951293\n",
      "5 0.742984170696 -0.00782662186367 0.00487538061235 34309.1041049 0.0932674638437 0.680015613727\n",
      "6 0.743371011126 -0.007850695851 0.00413833859174 34304.8010461 0.0932562961287 0.679650252195\n",
      "7 0.74369937045 -0.00775174626052 0.00343069457704 34301.9871318 0.0932486762694 0.679366571784\n",
      "8 0.743971581272 -0.00756876837637 0.00276454335913 34300.0983602 0.0932432648614 0.679139708467\n",
      "9 0.744190935868 -0.00732963100225 0.00214623802788 34298.8002671 0.0932392707016 0.678956062558\n",
      "10 0.744361230601 -0.00705431331115 0.00157853593047 34297.8874507 0.0932362128798 0.678806249283\n",
      "11 0.744486480621 -0.00675719826731 0.00106189429505 34297.2309549 0.0932337927961 0.678681802589\n",
      "12 0.744570737354 -0.00644866976665 0.00059529703048 34296.7483595 0.093231821282 0.678577235527\n",
      "13 0.744617971607 -0.00613622519524 0.000176799609364 34296.3860801 0.0932301759405 0.678488832891\n",
      "14 0.744631999893 -0.00582525707802 -0.000196105225306 34296.1086627 0.0932287757346 0.678413767842\n",
      "15 0.744616439789 -0.0055196091408 -0.000526239644824 34295.8922129 0.0932275656437 0.678349774011\n",
      "16 0.744574684942 -0.00522197735524 -0.000816572248046 34295.7203194 0.0932265072849 0.678295023998\n",
      "17 0.744509893455 -0.00493420302406 -0.00107010379062 34295.5814946 0.0932255731097 0.678247956745\n",
      "18 0.744424985333 -0.00465748947941 -0.00128979039256 34295.4675504 0.0932247427676 0.67820736815\n",
      "19 0.744322646026 -0.0043925638557 -0.00147849287568 34295.3725525 0.0932240007954 0.678172303985\n",
      "20 0.744205333991 -0.00413979877263 -0.00163894442906 34295.292137 0.0932233351262 0.678141977405\n",
      "21 0.744075290817 -0.00389930437179 -0.0017737311748 34295.2230555 0.0932227361111 0.678115742199\n",
      "22 0.743934552896 -0.00367099818971 -0.00188528181858 34295.1628666 0.0932221958658 0.678093070039\n",
      "23 0.743784963913 -0.00345465831666 -0.00197586367791 34295.1097218 0.0932217078249 0.678073489956\n",
      "24 0.743628187649 -0.00324996386478 -0.0020475831535 34295.0622148 0.0932212664323 0.67805660249\n",
      "25 0.743465720755 -0.00305652575159 -0.00210238925194 34295.0192717 0.0932208669214 0.678042076266\n",
      "26 0.743298905232 -0.00287391006556 -0.00214207915474 34294.9800715 0.0932205051553 0.678029619259\n",
      "27 0.743128940487 -0.00270165573556 -0.0021683051062 34294.9439855 0.093220177509 0.678018991878\n",
      "28 0.742956894826 -0.00253928781988 -0.00218258209362 34294.9105325 0.0932198807802 0.678009976614\n",
      "29 0.742783716348 -0.00238632742427 -0.00218629593964 34294.8793436 0.0932196121209 0.678002378445\n",
      "30 0.742610243191 -0.00224229902604 -0.00218071153412 34294.8501363 0.0932193689835 0.677996037238\n",
      "31 0.742437213134 -0.00210673580422 -0.00216698101204 34294.8226932 0.0932191490788 0.677990816512\n",
      "32 0.742265272534 -0.00197918343906 -0.00214615174215 34294.7968462 0.0932189503408 0.677986573223\n",
      "33 0.742094984646 -0.00185920273982 -0.0021191740346 34294.7724646 0.0932187708997 0.677983194068\n",
      "34 0.741926837324 -0.00174637137857 -0.00208690850719 34294.7494449 0.0932186090575 0.677980579527\n",
      "35 0.741761250132 -0.00164028494494 -0.00205013307406 34294.727704 0.0932184632697 0.677978640348\n",
      "36 0.741598580912 -0.00154055748862 -0.00200954953725 34294.7071734 0.093218332128 0.677977295126\n",
      "37 0.741439131821 -0.00144682167812 -0.00196578977448 34294.6877949 0.0932182143463 0.677976472319\n",
      "38 0.741283154878 -0.00135872867561 -0.0019194215256 34294.6695177 0.0932181087494 0.677976110234\n",
      "39 0.741130857056 -0.00127594780444 -0.00187095378614 34294.6522959 0.0932180142612 0.677976151188\n"
     ]
    }
   ],
   "source": [
    "# fit linear model: ratio(u, i) = alpha + beta_u + beta_i\n",
    "\n",
    "# parameters\n",
    "max_iter = 40\n",
    "lam = 1\n",
    "alpha = 0.7704\n",
    "beta_us = np.random.normal(0, 0.5, (num_users,))\n",
    "beta_is = np.random.normal(0, 0.5, (num_items,))\n",
    "\n",
    "cost, valid_mse, alpha, beta_us, beta_is = train_and_eval(max_iter, \n",
    "                                                          lam, alpha, beta_us, beta_is, \n",
    "                                                          train_ratio_array, valid_ratio_array, valid_data,\n",
    "                                                          print_step=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('betas.pickle', 'w') as f:\n",
    "    pickle.dump([beta_us, beta_is], f)\n",
    "    \n",
    "with open('betas.pickle') as f:\n",
    "    beta_us, beta_is = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # simulate alpha, beta_us, beta_is by hand\n",
    "\n",
    "# # get global average\n",
    "# train_helpfuls = np.array([d['helpful']['nHelpful'] for d in train_data])\n",
    "# train_outofs =  np.array([d['helpful']['outOf'] for d in train_data])\n",
    "# train_avg_ratio = np.sum(train_helpfuls) / np.sum(train_outofs.astype(float))\n",
    "\n",
    "# # get average for a user\n",
    "# users_outof = dict()\n",
    "# users_helpful = dict()\n",
    "\n",
    "# for d in train_data:\n",
    "#     user_id = d['reviewerID']\n",
    "#     users_outof[user_id] = users_outof.get(user_id, 0.0) + float(d['helpful']['outOf'])\n",
    "#     users_helpful[user_id] = users_helpful.get(user_id, 0.0) + float(d['helpful']['nHelpful'])\n",
    "    \n",
    "# users_ratio = dict()\n",
    "# for user_id in users_outof:\n",
    "#     if users_outof[user_id] != 0:\n",
    "#         users_ratio[user_id] = users_helpful[user_id] / users_outof[user_id]\n",
    "#     else:\n",
    "#         users_outof[user_id] = train_avg_ratio\n",
    "\n",
    "# # simulate!\n",
    "# alpha = train_avg_ratio\n",
    "# beta_us = np.zeros((num_users,))\n",
    "# beta_is = np.zeros((num_items,))\n",
    "\n",
    "# for user_id, ratio_value in users_ratio.iteritems():\n",
    "#     beta_us[user_id_map_index[user_id]] = ratio_value - alpha\n",
    "    \n",
    "# # get valid mae\n",
    "# print(get_valid_mae(valid_data, alpha, beta_us, beta_is))\n",
    "# print(get_valid_mae(train_data, alpha, beta_us, beta_is))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # with the initialized value, do update\n",
    "# # doesn't quite work, since objective not the same\n",
    "# max_iter = 30\n",
    "# lam = 1.0\n",
    "\n",
    "# cost, valid_mse, alpha, beta_us, beta_is = train_and_eval(max_iter, \n",
    "#                                                           lam, alpha, beta_us, beta_is, \n",
    "#                                                           train_ratio_array, valid_ratio_array, valid_data,\n",
    "#                                                           print_step=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
