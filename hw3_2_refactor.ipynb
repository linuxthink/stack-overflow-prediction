{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import cPickle as pickle\n",
    "import time\n",
    "from __future__ import print_function\n",
    "from collections import defaultdict\n",
    "\n",
    "data_root = '/home/linuxthink/data/CSE255/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.4010329247\n"
     ]
    }
   ],
   "source": [
    "# laod raw data\n",
    "start_time = time.time()\n",
    "all_data = pickle.load(open(data_root + \"all_data.pickle\", \"rb\"))\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get train and test set\n",
    "num_all = len(all_data)\n",
    "num_train = 900000\n",
    "num_valid = 100000\n",
    "assert num_train + num_valid == num_all\n",
    "\n",
    "train_data = all_data[:num_train]\n",
    "valid_data = all_data[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre-process 0: build id <-> index infastructure\n",
    "\n",
    "# get all items and users\n",
    "item_ids = sorted(list(set([d['itemID'] for d in all_data])))\n",
    "user_ids = sorted(list(set([d['reviewerID'] for d in all_data])))\n",
    "\n",
    "# user and item numbers\n",
    "num_items = len(item_ids)\n",
    "num_users = len(user_ids)\n",
    "\n",
    "# build id <-> index map\n",
    "item_id_map_index = dict()\n",
    "item_index_map_id = dict()\n",
    "for index, item_id in enumerate(item_ids):\n",
    "    item_id_map_index[item_id] = index\n",
    "    item_index_map_id[index] = item_id\n",
    "    \n",
    "user_id_map_index = dict()\n",
    "user_index_map_id = dict()\n",
    "for index, user_id in enumerate(user_ids):\n",
    "    user_id_map_index[user_id] = index\n",
    "    user_index_map_id[index] = user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre-process 1: build train_rating_array, valid_rating_array\n",
    "\n",
    "# build array [user_index, item_index, rating]\n",
    "train_rating_array = []\n",
    "for d in train_data:\n",
    "    user_index = user_id_map_index[d['reviewerID']]\n",
    "    item_index = item_id_map_index[d['itemID']]\n",
    "    rating = d['rating']\n",
    "    train_rating_array.append([user_index, item_index, rating])\n",
    "train_rating_array = np.array(train_rating_array).astype(int)\n",
    "\n",
    "# build array [user_index, item_index, rating]\n",
    "valid_rating_array = []\n",
    "for d in valid_data:\n",
    "    user_index = user_id_map_index[d['reviewerID']]\n",
    "    item_index = item_id_map_index[d['itemID']]\n",
    "    rating = d['rating']\n",
    "    valid_rating_array.append([user_index, item_index, rating])\n",
    "valid_rating_array = np.array(valid_rating_array).astype(int)\n",
    "\n",
    "# build array [user_index, item_index, rating]\n",
    "all_rating_array = []\n",
    "for d in all_data:\n",
    "    user_index = user_id_map_index[d['reviewerID']]\n",
    "    item_index = item_id_map_index[d['itemID']]\n",
    "    rating = d['rating']\n",
    "    all_rating_array.append([user_index, item_index, rating])\n",
    "all_rating_array = np.array(all_rating_array).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre-process 2: # utility and update functions\n",
    "def get_valid_mse(lam, alpha, beta_us, beta_is, rating_array, valid_rating_array):\n",
    "    predicts = alpha + beta_us[valid_rating_array[:, 0]] + beta_is[valid_rating_array[:, 1]]\n",
    "    ratings = valid_rating_array[:, 2].astype(float)\n",
    "    return (1. / valid_rating_array.shape[0]) * np.sum((predicts - ratings) ** 2.0)\n",
    "\n",
    "def get_cost(lam, alpha, beta_us, beta_is, rating_array, Ruis, Rius):\n",
    "    predicts = alpha + beta_us[rating_array[:, 0]] + beta_is[rating_array[:, 1]]\n",
    "    ratings = rating_array[:, 2].astype(float)\n",
    "    return np.sum((predicts - ratings) ** 2.) + lam * (np.sum(beta_us ** 2.) + np.sum(beta_is ** 2.))\n",
    "    \n",
    "def alpha_update(lam, alpha, beta_us, beta_is, rating_array, Ruis, Rius):\n",
    "    sum_Rui = np.sum(rating_array[:, 2])\n",
    "    sum_beta_u = np.sum(beta_us[rating_array[:, 0]]) # fancy indexing\n",
    "    sum_beta_i = np.sum(beta_is[rating_array[:, 1]]) # fancy indexing\n",
    "    return (sum_Rui - sum_beta_u - sum_beta_i) / rating_array.shape[0]\n",
    "\n",
    "def beta_us_update(lam, alpha, beta_us, beta_is, rating_array, Ruis, Rius):\n",
    "    new_beta_us = np.zeros_like(beta_us)\n",
    "    for user_index in xrange(num_users):\n",
    "        # [the set of items] reviewed by user u\n",
    "        Iu = Ruis[user_index].keys()\n",
    "        Iu_size = len(Iu)\n",
    "        # sums\n",
    "        sum_Rui = np.sum(Ruis[user_index].values())\n",
    "        sum_alpha = Iu_size * alpha\n",
    "        sum_beta_i = np.sum(beta_is[Iu])\n",
    "        # write result\n",
    "        new_beta_us[user_index] = float(sum_Rui - sum_alpha - sum_beta_i) / (lam + Iu_size)\n",
    "    return new_beta_us\n",
    "\n",
    "def beta_is_update(lam, alpha, beta_us, beta_is, rating_array, Ruis, Rius):\n",
    "    new_beta_is = np.zeros_like(beta_is)\n",
    "    for item_index in xrange(num_items):\n",
    "        # [the set of users] reviewd item i\n",
    "        Ui = Rius[item_index].keys()\n",
    "        Ui_size = len(Ui)\n",
    "        # sums\n",
    "        sum_Rui = np.sum(Rius[item_index].values())\n",
    "        sum_alpha = Ui_size * alpha\n",
    "        sum_beta_u = np.sum(beta_us[Ui])\n",
    "        # write result\n",
    "        new_beta_is[item_index] = float(sum_Rui - sum_alpha - sum_beta_u) / (lam + Ui_size)\n",
    "    return new_beta_is\n",
    "\n",
    "def train_and_eval(max_iter, \n",
    "                   lam, alpha, beta_us, beta_is, \n",
    "                   rating_array, valid_rating_array,\n",
    "                   print_step = False):\n",
    "    \n",
    "    # build Mapping of Ruis and Rius\n",
    "    Ruis = defaultdict(dict)\n",
    "    Rius = defaultdict(dict)\n",
    "    # Iu = Ruis[user_index].keys() # [the set of items] reviewed by user u\n",
    "    # Ui = Ruis[item_index].keys() # [the set of users] reviewed item i\n",
    "    for t in rating_array:\n",
    "        user_index = t[0]\n",
    "        item_index = t[1]\n",
    "        rating = t[2]\n",
    "        Ruis[user_index][item_index] = rating\n",
    "        Rius[item_index][user_index] = rating\n",
    "    \n",
    "    # train on this dataset\n",
    "    for i in xrange(max_iter):\n",
    "        alpha = alpha_update(lam, alpha, beta_us, beta_is, rating_array, Ruis, Rius)\n",
    "        beta_us = beta_us_update(lam, alpha, beta_us, beta_is, rating_array, Ruis, Rius)\n",
    "        beta_is = beta_is_update(lam, alpha, beta_us, beta_is, rating_array, Ruis, Rius)\n",
    "        if print_step:\n",
    "            cost = get_cost(lam, alpha, beta_us, beta_is, rating_array, Ruis, Rius)\n",
    "            valid_mse = get_valid_mse(lam, alpha, beta_us, beta_is, \n",
    "                                      rating_array, valid_rating_array)\n",
    "            print(i, cost, valid_mse)\n",
    "    \n",
    "    cost = get_cost(lam, alpha, beta_us, beta_is, rating_array, Ruis, Rius)\n",
    "    valid_mse = get_valid_mse(lam, alpha, beta_us, beta_is, rating_array, valid_rating_array)\n",
    "    \n",
    "    return(cost, valid_mse, alpha, beta_us, beta_is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 4.21898777778\n",
      "valid_mse 0.969062751573\n"
     ]
    }
   ],
   "source": [
    "# 3.5 average predictor (using index based sorted list)\n",
    "# get averaged rating\n",
    "alpha = np.mean(train_rating_array[:, 2])\n",
    "print('alpha', alpha)\n",
    "\n",
    "# calculate mse\n",
    "valid_ratings = valid_rating_array[:, 2]\n",
    "valid_mse = (1. / valid_rating_array.shape[0]) * np.sum((valid_ratings - alpha) ** 2.0)\n",
    "print('valid_mse', valid_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541295.851161 0.696104838292\n"
     ]
    }
   ],
   "source": [
    "# 3.6 fit baseline model: rating(u, i) = alpha + beta_u + beta_i\n",
    "\n",
    "# set training\n",
    "max_iter = 30\n",
    "\n",
    "# parameters\n",
    "lam = 1.0\n",
    "alpha = 0.0\n",
    "beta_us = np.random.normal(0, 0.5, (num_users,))\n",
    "beta_is = np.random.normal(0, 0.5, (num_items,))\n",
    "\n",
    "cost, valid_mse, alpha, beta_us, beta_is = train_and_eval(max_iter, \n",
    "                                                          lam, alpha, beta_us, beta_is, \n",
    "                                                          train_rating_array, valid_rating_array)\n",
    "print(cost, valid_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user, largest U516357151\n",
      "user, smallest U512598315\n",
      "item, largest I245219975\n",
      "item, smallest I502194676\n"
     ]
    }
   ],
   "source": [
    "# 3.7 report the user and item id that have the largest and smallest values of beta\n",
    "\n",
    "print('user, largest', user_index_map_id[np.argmax(beta_us)])\n",
    "print('user, smallest', user_index_map_id[np.argmin(beta_us)])\n",
    "\n",
    "print('item, largest', item_index_map_id[np.argmax(beta_is)])\n",
    "print('item, smallest', item_index_map_id[np.argmin(beta_is)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 544098.523595 0.723812782094\n",
      "1 526574.000267 0.703764970551\n",
      "2 525679.849498 0.702909347648\n",
      "3 525454.616149 0.702652242602\n",
      "4 525348.801929 0.702517961378\n",
      "0.001 525348.801929 0.702517961378\n",
      "0 544230.811429 0.723719078081\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a0d93e82d4b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m                                         \u001b[0mlam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_us\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_is\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                                         \u001b[0mtrain_rating_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_rating_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                                         print_step=True)\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-1f80a7f8cc65>\u001b[0m in \u001b[0;36mtrain_and_eval\u001b[1;34m(max_iter, lam, alpha, beta_us, beta_is, rating_array, valid_rating_array, print_step)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_us\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_is\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrating_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRuis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRius\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mbeta_us\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeta_us_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_us\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_is\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrating_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRuis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRius\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[0mbeta_is\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeta_is_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_us\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_is\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrating_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRuis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRius\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprint_step\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-1f80a7f8cc65>\u001b[0m in \u001b[0;36mbeta_us_update\u001b[1;34m(lam, alpha, beta_us, beta_is, rating_array, Ruis, Rius)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0msum_Rui\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRuis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0msum_alpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIu_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0msum_beta_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta_is\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mIu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;31m# write result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mnew_beta_us\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum_Rui\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msum_alpha\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msum_beta_i\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlam\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mIu_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 3.8 search for the best lam\n",
    "lams = [0.001, 0.01, 0.1, 1.0, 10, 100]\n",
    "max_iter = 5\n",
    "\n",
    "# init variables\n",
    "alpha = 0.0\n",
    "beta_us = np.random.normal(0, 0.5, (num_users,))\n",
    "beta_is = np.random.normal(0, 0.5, (num_items,))\n",
    "\n",
    "results = []\n",
    "for lam in lams:\n",
    "    cost, mse, _, _, _ = train_and_eval(max_iter, \n",
    "                                        lam, alpha, beta_us, beta_is, \n",
    "                                        train_rating_array, valid_rating_array,\n",
    "                                        print_step=True)\n",
    "    print(lam, cost, mse)\n",
    "    results.append([lam, cost, mse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 623274.998516 0.61471460324\n",
      "1 606265.972085 0.596871920416\n",
      "2 605575.176154 0.595873487936\n",
      "3 605447.240888 0.595636939027\n",
      "4 605408.59391 0.595542244584\n",
      "5 605393.742056 0.595492402759\n",
      "6 605386.823703 0.595461370772\n",
      "7 605382.979792 0.595439914564\n",
      "8 605380.504561 0.595424109402\n",
      "9 605378.727325 0.595412020918\n",
      "10 605377.352458 0.595402563455\n",
      "11 605376.233816 0.59539505853\n",
      "12 605375.29123 0.595389046393\n",
      "13 605374.476847 0.595384197429\n",
      "14 605373.760215 0.595380266238\n",
      "15 605373.121008 0.595377065484\n",
      "16 605372.545122 0.59537444973\n",
      "17 605372.022439 0.595372304738\n",
      "18 605371.545466 0.595370540022\n",
      "19 605371.10848 0.59536908346\n",
      "20 605370.706976 0.595367877288\n",
      "21 605370.337304 0.595366875065\n",
      "22 605369.996429 0.595366039332\n",
      "23 605369.681769 0.595365339799\n",
      "24 605369.391083 0.595364751913\n",
      "25 605369.122397 0.595364255735\n",
      "26 605368.87395 0.59536383504\n",
      "27 605368.644153 0.595363476609\n",
      "28 605368.431566 0.59536316965\n",
      "29 605368.234875 0.595362905344\n",
      "605368.234875 0.595362905344\n"
     ]
    }
   ],
   "source": [
    "# now train on all data\n",
    "max_iter = 30\n",
    "\n",
    "# init variables\n",
    "lam = 1.0\n",
    "alpha = 0.0\n",
    "beta_us = np.random.normal(0, 0.5, (num_users,))\n",
    "beta_is = np.random.normal(0, 0.5, (num_items,))\n",
    "\n",
    "cost, mse, alpha, beta_us, beta_is = train_and_eval(max_iter, \n",
    "                                                    lam, alpha, beta_us, beta_is, \n",
    "                                                    all_rating_array, valid_rating_array,\n",
    "                                                    print_step=True)\n",
    "print(cost, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get header_str and user_item_ids to predict\n",
    "with open('pairs_Rating.txt') as f:\n",
    "    # read and strip lines\n",
    "    lines = [l.strip() for l in f.readlines()]\n",
    "    # stirip out the headers\n",
    "    header_str = lines.pop(0)\n",
    "    # get a list of user_item_ids\n",
    "    user_item_ids = [l.split('-') for l in lines]\n",
    "    \n",
    "# write to output file\n",
    "f = open('predictions_Rating.txt', 'w')\n",
    "print(header_str, file=f)\n",
    "for user_id, item_id in user_item_ids:\n",
    "    rating = alpha + beta_us[user_id_map_index[user_id]] + beta_is[item_id_map_index[item_id]]\n",
    "    rating = min(5.0, rating)\n",
    "    rating = max(0.0, rating)\n",
    "    print('%s-%s,%s' % (user_id, item_id, rating), file=f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
