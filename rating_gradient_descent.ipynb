{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import cPickle as pickle\n",
    "import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# laod raw data\n",
    "start_time = time.time()\n",
    "all_data = pickle.load(open(\"all_data.pickle\", \"rb\"))\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get train and test set\n",
    "train_data = all_data[:900000]\n",
    "valid_data = all_data[900000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre-process 0: build id <-> index infastructure\n",
    "\n",
    "# get all items and users\n",
    "user_ids = sorted(list(set([d['reviewerID'] for d in all_data])))\n",
    "item_ids = sorted(list(set([d['itemID'] for d in all_data])))\n",
    "\n",
    "# user and item numbers\n",
    "num_users = len(user_ids)\n",
    "num_items = len(item_ids)\n",
    "\n",
    "# build id <-> index map\n",
    "item_id_map_index = dict()\n",
    "item_index_map_id = dict()\n",
    "for index, item_id in enumerate(item_ids):\n",
    "    item_id_map_index[item_id] = index\n",
    "    item_index_map_id[index] = item_id\n",
    "    \n",
    "user_id_map_index = dict()\n",
    "user_index_map_id = dict()\n",
    "for index, user_id in enumerate(user_ids):\n",
    "    user_id_map_index[user_id] = index\n",
    "    user_index_map_id[index] = user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre-process 1: build train_rating_array, valid_rating_array\n",
    "\n",
    "# build array [user_index, item_index, rating]\n",
    "train_rating_array = []\n",
    "for d in train_data:\n",
    "    user_index = user_id_map_index[d['reviewerID']]\n",
    "    item_index = item_id_map_index[d['itemID']]\n",
    "    rating = d['rating']\n",
    "    train_rating_array.append([user_index, item_index, rating])\n",
    "train_rating_array = np.array(train_rating_array).astype(int)\n",
    "\n",
    "# build array [user_index, item_index, rating]\n",
    "valid_rating_array = []\n",
    "for d in valid_data:\n",
    "    user_index = user_id_map_index[d['reviewerID']]\n",
    "    item_index = item_id_map_index[d['itemID']]\n",
    "    rating = d['rating']\n",
    "    valid_rating_array.append([user_index, item_index, rating])\n",
    "valid_rating_array = np.array(valid_rating_array).astype(int)\n",
    "\n",
    "# build array [user_index, item_index, rating]\n",
    "all_rating_array = []\n",
    "for d in all_data:\n",
    "    user_index = user_id_map_index[d['reviewerID']]\n",
    "    item_index = item_id_map_index[d['itemID']]\n",
    "    rating = d['rating']\n",
    "    all_rating_array.append([user_index, item_index, rating])\n",
    "all_rating_array = np.array(all_rating_array).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mse(ratings, ratings_predict):\n",
    "    return np.mean((np.array(ratings.astype('float')) - \n",
    "                    np.array(ratings_predict).astype('float')) ** 2.)\n",
    "\n",
    "def get_rmse(ratings, ratings_predict):\n",
    "    return get_mse(ratings, ratings_predict) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# global variableds\n",
    "K = 10\n",
    "lam = 0.02\n",
    "alpha = np.mean(train_rating_array[:, 2])\n",
    "\n",
    "user_num = len(user_ids)\n",
    "item_num = len(item_ids)\n",
    "theta = init_theta(K) # all parameters\n",
    "\n",
    "[a, b, c, d] = unpack(theta)\n",
    "theta_new = pack(a,b,c,d)\n",
    "assert(np.array_equal(theta, theta_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pack(beta_users, beta_items, gamma_users, gamma_items):\n",
    "    return np.concatenate((beta_users.ravel(),\n",
    "                           beta_items.ravel(),\n",
    "                           gamma_users.ravel(),\n",
    "                           gamma_items.ravel()))\n",
    "\n",
    "def unpack(theta):\n",
    "    curr_ind = 0\n",
    "    beta_users = theta[curr_ind : curr_ind + user_num]\n",
    "    curr_ind += user_num\n",
    "    beta_items = theta[curr_ind : curr_ind + item_num]\n",
    "    curr_ind += item_num\n",
    "    gamma_users = theta[curr_ind : curr_ind + K * user_num].reshape((K, user_num))\n",
    "    curr_ind += K * user_num\n",
    "    gamma_items = theta[curr_ind :].reshape((K, item_num))\n",
    "    return [beta_users, beta_items, gamma_users, gamma_items]\n",
    "\n",
    "def init_theta(K):\n",
    "    beta_users = np.random.normal(0, 0.5, (user_num, ))\n",
    "    beta_items = np.random.normal(0, 0.5, (item_num, ))\n",
    "    gamma_users = np.random.normal(0, 0.5, (K, user_num))\n",
    "    gamma_items = np.random.normal(0, 0.5, (K, item_num))\n",
    "    return pack(beta_users, beta_items, gamma_users, gamma_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def objective(theta):\n",
    "    [beta_users, beta_items, gamma_users, gamma_items] = unpack(theta)\n",
    "    cost = 0.0\n",
    "    for datum in train_rating_array:\n",
    "        user_index = datum[0]\n",
    "        item_index = datum[1]\n",
    "        cost += (float(alpha)\n",
    "                 + beta_users[user_index]\n",
    "                 + beta_items[item_index]\n",
    "                 + np.dot(gamma_users[:, user_index], gamma_items[:, item_index])\n",
    "                 - float(datum[2])\n",
    "                ) ** 2.0\n",
    "    cost += lam * (np.linalg.norm(theta) ** 2.0)\n",
    "    return 0.5 * cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient(theta):\n",
    "    # unpack\n",
    "    [beta_users, beta_items, gamma_users, gamma_items] = unpack(theta)\n",
    "    # init gradient buffers\n",
    "    beta_users_grad = np.zeros((user_num, ))\n",
    "    beta_items_grad = np.zeros((item_num, ))\n",
    "    gamma_users_grad = np.zeros((K, user_num))\n",
    "    gamma_items_grad = np.zeros((K, item_num))\n",
    "    # accumulate gradients\n",
    "    for datum in train_rating_array:\n",
    "        user_index = datum[0]\n",
    "        item_index = datum[1]\n",
    "        prediction = (float(alpha)\n",
    "                      + beta_users[user_index]\n",
    "                      + beta_items[item_index]\n",
    "                      + np.dot(gamma_users[:, user_index], gamma_items[:, item_index]))\n",
    "        common_offset = (prediction - float(datum[2]))\n",
    "\n",
    "        beta_users_grad[user_index] += common_offset\n",
    "        beta_items_grad[item_index] += common_offset\n",
    "        gamma_users_grad[:, user_index] += common_offset * gamma_items[:, item_index]\n",
    "        gamma_items_grad[:, item_index] += common_offset * gamma_users[:, user_index]\n",
    "    # pack\n",
    "    grad = pack(beta_users_grad,\n",
    "                beta_items_grad,\n",
    "                gamma_users_grad,\n",
    "                gamma_items_grad)\n",
    "    # reguilization gradient\n",
    "    grad = grad + lam * theta\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_one_rating(user_index, item_index, theta):\n",
    "    user_index = int(user_index)\n",
    "    item_index = int(item_index)\n",
    "    [beta_users, beta_items, gamma_users, gamma_items] = unpack(theta)\n",
    "    \n",
    "    # user\n",
    "    beta_user = beta_users[user_index]\n",
    "    gamma_user = gamma_users[user_index]\n",
    "    \n",
    "    # item\n",
    "    beta_item = beta_items[item_index]\n",
    "    gamma_item = gamma_items[item_index]\n",
    "    \n",
    "    return alpha + beta_user + beta_item + np.dot(gamma_user, gamma_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_and_get_rmse(data, theta):\n",
    "    ratings_predict = [predict_one_rating(user_index, item_index, theta) \n",
    "                       for user_index, item_index in data[:, :2]]\n",
    "    gt_predict = data[:, 2]\n",
    "    return get_rmse(pd_ratings, gt_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def progress_callback(theta):\n",
    "    print(\"train rmse:\", test_and_get_rmse(train_rating_array, theta))\n",
    "    print(\"valid rmse:\", test_and_get_rmse(valid_rating_array, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "res = minimize(objective, \n",
    "               theta, \n",
    "               method='L-BFGS-B', \n",
    "               jac=gradient, \n",
    "               options={'disp': True, 'maxiter': 200},\n",
    "               callback=progress_callback)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
