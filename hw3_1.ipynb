{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import cPickle as pickle\n",
    "import time\n",
    "import os\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.5558400154\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "all_data = pickle.load(open(\"all_data.pickle\", \"rb\"))\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Books']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[9]['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_size = len(all_data)\n",
    "train_data = all_data[:100000]\n",
    "valid_data = all_data[900000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'itemID': 'I572782694', 'rating': 5.0, 'helpful': {'nHelpful': 0, 'outOf': 0}, 'reviewText': 'favorite of the series...May not have been as steamy as some of the others...but the characters, their depth, and believability were amazing.  wanted to curl up with Devlin and make it all better(wink wink). an amazing series...found Laura Kate when I stumbled onto Hearts in Darkness(one of my all time faves)...this series ranks up there with my Kresley Cole and Gena Showalter favorites.', 'reviewerID': 'U243261361', 'summary': 'Loved it', 'unixReviewTime': 1399075200, 'category': [['Books']], 'reviewTime': '05 3, 2014'}\n"
     ]
    }
   ],
   "source": [
    "datum = train_data[0]\n",
    "print(datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_abs_error(helpfuls, helpfuls_predict):\n",
    "    return np.sum(np.abs(helpfuls_predict - helpfuls.astype(float))) / helpfuls.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg helpfulness ratio 0.771613890384\n"
     ]
    }
   ],
   "source": [
    "# 1.1 alpha as global mean of helpful ratio\n",
    "train_helpfuls = np.array([d['helpful']['nHelpful'] for d in train_data])\n",
    "train_outofs =  np.array([d['helpful']['outOf'] for d in train_data])\n",
    "alpha = np.sum(train_helpfuls) / np.sum(train_outofs.astype(float))\n",
    "print('avg helpfulness ratio', alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_abs_error 0.707253269408\n"
     ]
    }
   ],
   "source": [
    "# 1.2 mean absolute error in validation set\n",
    "valid_helpfuls = np.array([d['helpful']['nHelpful'] for d in valid_data])\n",
    "valid_outofs =  np.array([d['helpful']['outOf'] for d in valid_data])\n",
    "valid_helpfuls_predict = valid_outofs * alpha\n",
    "print('mean_abs_error', get_mean_abs_error(valid_helpfuls, valid_helpfuls_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1.3 fit model\n",
    "# theta[0] + theta[1] * #words_in_review + theta[2] * review_star_rating\n",
    "\n",
    "###### WARING !!! WRONG SINCE SOME ENTRY IS REMOVED !!! #######\n",
    "def get_feature(d):\n",
    "    num_review_words = len(d['reviewText'].split())\n",
    "    star = d['rating']\n",
    "    return [1.0, num_review_words, star]\n",
    "\n",
    "def get_ratio(d):\n",
    "    return float(d['helpful']['nHelpful']) / float(d['helpful']['outOf'])\n",
    "\n",
    "# linear regression, ignore devided by zero data\n",
    "########## WARNING !!!! Modify here to fit either train data or all data\n",
    "train_xs = np.array([get_feature(d) for d in train_data if d['helpful']['outOf'] != 0])\n",
    "train_ys = np.array([get_ratio(d) for d in train_data if d['helpful']['outOf'] != 0])\n",
    "\n",
    "theta, residuals, rank, s = np.linalg.lstsq(train_xs, train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.58745758e-01,   1.42189987e-04,   5.97109787e-02])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae 0.683704925818\n"
     ]
    }
   ],
   "source": [
    "# on train set\n",
    "train_features = np.array([get_feature(d) for d in train_data])\n",
    "train_helpfuls = np.array([d['helpful']['nHelpful'] for d in train_data])\n",
    "train_outofs = np.array([d['helpful']['outOf'] for d in train_data])\n",
    "train_helpfuls_predict = np.dot(train_features, theta) * train_outofs\n",
    "print('mae', get_mean_abs_error(train_helpfuls, train_helpfuls_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae 0.688017608167\n"
     ]
    }
   ],
   "source": [
    "# on valid set\n",
    "valid_features = np.array([get_feature(d) for d in valid_data])\n",
    "valid_helpfuls = np.array([d['helpful']['nHelpful'] for d in valid_data])\n",
    "valid_outofs = np.array([d['helpful']['outOf'] for d in valid_data])\n",
    "valid_helpfuls_predict = np.dot(valid_features, theta) * valid_outofs\n",
    "print('mae', get_mean_abs_error(valid_helpfuls, valid_helpfuls_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load helpful_data.json\n",
    "test_data = pickle.load(open(\"helpful_data.pickle\", \"rb\"))\n",
    "\n",
    "# on test set\n",
    "test_features = np.array([get_feature(d) for d in test_data])\n",
    "test_outofs = np.array([d['helpful']['outOf'] for d in test_data])\n",
    "test_helpfuls_predict = np.dot(test_features, theta) * test_outofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load 'pairs_Helpful.txt'\n",
    "# get header_str and user_item_outofs\n",
    "with open('pairs_Helpful.txt') as f:\n",
    "    # read and strip lines\n",
    "    lines = [l.strip() for l in f.readlines()]\n",
    "    # stirip out the headers\n",
    "    header_str = lines.pop(0)\n",
    "    # get a list of user_item_ids\n",
    "    user_item_outofs = [l.split('-') for l in lines]\n",
    "    user_item_outofs = [[d[0], d[1], float(d[2])] for d in user_item_outofs]\n",
    "    \n",
    "# make sure `data.json` and `pairs_Helpful.txt` the same order\n",
    "for (user_id, item_id, outof), d in zip(user_item_outofs, test_data):\n",
    "    assert d['reviewerID'] == user_id\n",
    "    assert d['itemID'] == item_id\n",
    "    assert d['helpful']['outOf'] == outof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write to output file\n",
    "f = open('predictions_Helpful.txt', 'w')\n",
    "print(header_str, file=f)\n",
    "for (user_id, item_id, outof), test_helpful_predict in zip(user_item_outofs, test_helpfuls_predict):\n",
    "    print('%s-%s-%s,%s' % (user_id, item_id, int(outof), test_helpful_predict), file=f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
