{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import cPickle as pickle\n",
    "import time\n",
    "import os\n",
    "\n",
    "data_root = os.path.expanduser(\"~\") + '/data/CSE255/'\n",
    "\n",
    "import cvxopt as co\n",
    "from l1 import l1\n",
    "\n",
    "# natural language processing\n",
    "import nltk\n",
    "import nltk.data\n",
    "import string\n",
    "sentence_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "punctuation = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.125041008\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "all_data = pickle.load(open(data_root + \"all_data.pickle\", \"rb\"))\n",
    "test_data = pickle.load(open(data_root + \"helpful_data.pickle\", \"rb\"))\n",
    "all_and_test_data = all_data + test_data\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # number of unique words in review text\n",
    "# num_unique_word = defaultdict(dict)\n",
    "# punctuation = set(string.punctuation)\n",
    "\n",
    "# def get_num_uique_word(d):\n",
    "#     wordCount = defaultdict(int)\n",
    "#     for w in d[\"reviewText\"].split():\n",
    "#         w = \"\".join([c for c in w.lower() if c not in punctuation])\n",
    "#         w = stemmer.stem(w)\n",
    "#         wordCount[w] += 1\n",
    "#     return len(wordCount)\n",
    "\n",
    "# for idx, d in enumerate(all_and_test_data):\n",
    "#     if idx % 10000 == 0:\n",
    "#         print(\"%d of %d\" % (idx, len(all_and_test_data)))\n",
    "#     user_id = d['reviewerID']\n",
    "#     item_id = d['itemID']\n",
    "#     num_unique_word[user_id][item_id] = get_num_uique_word(d)\n",
    "    \n",
    "# # dump to pickle\n",
    "# pickle.dump(num_unique_word, open(data_root + \"num_unique_word.feature\", \"wb\"), \n",
    "#             protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# # read from pickle\n",
    "# num_unique_word = pickle.load(open(data_root + \"num_unique_word.feature\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 1050000\n",
      "10000 of 1050000\n",
      "20000 of 1050000\n",
      "30000 of 1050000\n",
      "40000 of 1050000\n",
      "50000 of 1050000\n",
      "60000 of 1050000\n",
      "70000 of 1050000\n",
      "80000 of 1050000\n",
      "90000 of 1050000\n",
      "100000 of 1050000\n",
      "110000 of 1050000\n",
      "120000 of 1050000\n",
      "130000 of 1050000\n",
      "140000 of 1050000\n",
      "150000 of 1050000\n",
      "160000 of 1050000\n",
      "170000 of 1050000\n",
      "180000 of 1050000\n",
      "190000 of 1050000\n",
      "200000 of 1050000\n",
      "210000 of 1050000\n",
      "220000 of 1050000\n",
      "230000 of 1050000\n",
      "240000 of 1050000\n",
      "250000 of 1050000\n",
      "260000 of 1050000\n",
      "270000 of 1050000\n",
      "280000 of 1050000\n",
      "290000 of 1050000\n",
      "300000 of 1050000\n",
      "310000 of 1050000\n",
      "320000 of 1050000\n",
      "330000 of 1050000\n",
      "340000 of 1050000\n",
      "350000 of 1050000\n",
      "360000 of 1050000\n",
      "370000 of 1050000\n",
      "380000 of 1050000\n",
      "390000 of 1050000\n",
      "400000 of 1050000\n",
      "410000 of 1050000\n",
      "420000 of 1050000\n",
      "430000 of 1050000\n",
      "440000 of 1050000\n",
      "450000 of 1050000\n",
      "460000 of 1050000\n",
      "470000 of 1050000\n",
      "480000 of 1050000\n",
      "490000 of 1050000\n",
      "500000 of 1050000\n",
      "510000 of 1050000\n",
      "520000 of 1050000\n",
      "530000 of 1050000\n",
      "540000 of 1050000\n",
      "550000 of 1050000\n",
      "560000 of 1050000\n",
      "570000 of 1050000\n",
      "580000 of 1050000\n",
      "590000 of 1050000\n",
      "600000 of 1050000\n",
      "610000 of 1050000\n",
      "620000 of 1050000\n",
      "630000 of 1050000\n",
      "640000 of 1050000\n",
      "650000 of 1050000\n",
      "660000 of 1050000\n",
      "670000 of 1050000\n",
      "680000 of 1050000\n",
      "690000 of 1050000\n",
      "700000 of 1050000\n",
      "710000 of 1050000\n",
      "720000 of 1050000\n",
      "730000 of 1050000\n",
      "740000 of 1050000\n",
      "750000 of 1050000\n",
      "760000 of 1050000\n",
      "770000 of 1050000\n",
      "780000 of 1050000\n",
      "790000 of 1050000\n",
      "800000 of 1050000\n",
      "810000 of 1050000\n",
      "820000 of 1050000\n",
      "830000 of 1050000\n",
      "840000 of 1050000\n",
      "850000 of 1050000\n",
      "860000 of 1050000\n",
      "870000 of 1050000\n",
      "880000 of 1050000\n",
      "890000 of 1050000\n",
      "900000 of 1050000\n",
      "910000 of 1050000\n",
      "920000 of 1050000\n",
      "930000 of 1050000\n",
      "940000 of 1050000\n",
      "950000 of 1050000\n",
      "960000 of 1050000\n",
      "970000 of 1050000\n",
      "980000 of 1050000\n",
      "990000 of 1050000\n",
      "1000000 of 1050000\n",
      "1010000 of 1050000\n",
      "1020000 of 1050000\n",
      "1030000 of 1050000\n",
      "1040000 of 1050000\n"
     ]
    }
   ],
   "source": [
    "# # writing style features\n",
    "# def get_feature_style(datum):\n",
    "#     style = dict()\n",
    "    \n",
    "#     # basic info\n",
    "#     user_id = datum['reviewerID']\n",
    "#     item_id = datum['itemID']\n",
    "#     review_summary = datum['summary']\n",
    "#     review_text = datum['reviewText']\n",
    "\n",
    "#     # punctuation_ratio\n",
    "#     review_text_len = float(len(review_text))\n",
    "#     punctuation_count = float(sum(1 for c in review_text if c in punctuation))\n",
    "#     punctuation_ratio = punctuation_count / review_text_len if review_text_len != 0 else 0.\n",
    "#     style['punctuation_count'] = punctuation_count\n",
    "#     style['punctuation_ratio'] = punctuation_ratio\n",
    "\n",
    "#     # capital letter word\n",
    "#     capital_count = float(sum(1 for c in review_text if c.isupper()))\n",
    "#     capital_ratio = capital_count / review_text_len if review_text_len != 0 else 0.\n",
    "#     style['capital_count'] = capital_count\n",
    "#     style['capital_ratio'] = capital_ratio\n",
    "\n",
    "#     # averaged word length\n",
    "#     review_text_pure = \"\".join([c for c in review_text if c not in punctuation])\n",
    "#     pure_words = review_text_pure.split()\n",
    "#     avg_word_len = sum(len(word) for word in pure_words) / float(len(pure_words)) if review_text_len != 0 else 0.\n",
    "#     style['avg_word_len'] = avg_word_len\n",
    "    \n",
    "#     # number of '?'\n",
    "#     question_count = float(review_text.count(\"?\"))\n",
    "#     style['question_count'] = question_count\n",
    "\n",
    "#     # number of '!'\n",
    "#     exclam_count = float(review_text.count(\"!\"))\n",
    "#     style['exclam_count'] = exclam_count\n",
    "\n",
    "#     # number of '!!'\n",
    "#     exclam_exclam_count = float(review_text.count(\"!!\"))\n",
    "#     style['exclam_exclam_count'] = exclam_exclam_count\n",
    "\n",
    "#     # number of '...'\n",
    "#     dotdotdot_count = float(review_text.count(\"...\"))\n",
    "#     style['dotdotdot_count'] = dotdotdot_count\n",
    "\n",
    "#     # lengths and redability\n",
    "#     style['num_unique_words'] = num_unique_word[user_id][item_id]\n",
    "#     style['num_words_summary'] = len(review_summary.split())\n",
    "    \n",
    "#     num_chars = float(sum(1 for c in review_text if c not in punctuation))\n",
    "#     num_words = float(len(pure_words))\n",
    "#     num_sentences = float(len(sentence_tokenizer.tokenize(review_text)))\n",
    "#     if num_words == 0 or num_sentences == 0:\n",
    "#         redability = 0\n",
    "#     else:\n",
    "#         redability = 4.71 * (num_chars / num_words) + 0.5 * (num_words / num_sentences) - 21.43\n",
    "#     style['num_chars'] = num_chars\n",
    "#     style['num_words'] = num_words\n",
    "#     style['num_sentences'] = num_sentences\n",
    "#     style['redability'] = redability\n",
    "        \n",
    "#     return style\n",
    "\n",
    "# # extract style feature\n",
    "# num_unique_word = pickle.load(open(data_root + \"num_unique_word.feature\", \"rb\"))\n",
    "# style_dict = defaultdict(dict)\n",
    "\n",
    "# for idx, d in enumerate(all_and_test_data):\n",
    "#     if idx % 10000 == 0:\n",
    "#         print(\"%d of %d\" % (idx, len(all_and_test_data)))\n",
    "#     user_id = d['reviewerID']\n",
    "#     item_id = d['itemID']\n",
    "#     style_dict[user_id][item_id] = get_feature_style(d)\n",
    "    \n",
    "# # dump to pickle\n",
    "# pickle.dump(style_dict, open(data_root + \"style_dict.feature\", \"wb\"), \n",
    "#             protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# # read from pickle\n",
    "# style_dict = pickle.load(open(data_root + \"style_dict.feature\", \"rb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
