{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "from itertools import groupby\n",
    "import nltk\n",
    "from dateutil import parser as dateparser\n",
    "\n",
    "data_path = os.path.join(os.path.expanduser(\"~\"), 'data/stack_overflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(f):\n",
    "    for l in open(f):\n",
    "        yield l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# regexs\n",
    "RE_NONALNUM = re.compile(r'\\W+')\n",
    "RE_NONANS = re.compile(r'[^\\w\\s]+')\n",
    "RE_DIGIT = re.compile(r'\\d+')\n",
    "RE_URL = re.compile(r'https?://')\n",
    "RE_NONWORD = re.compile(r'[A-Z\\d]+')\n",
    "\n",
    "# labels from 0 to 5, 0 for undefined\n",
    "all_status = ['not a real question', # 1\n",
    "              'not constructive',    # 2\n",
    "              'off topic',           # 3\n",
    "              'open',                # 4\n",
    "              'too localized']       # 5\n",
    "status_map_label = dict((k, int(i + 1)) for i, k in enumerate(all_status))\n",
    "\n",
    "\n",
    "def gen_datum_feature_dict(datum):\n",
    "    def norm(string):\n",
    "        return RE_NONANS.sub('', string).lower()\n",
    "\n",
    "    def norm_tag(string):\n",
    "        return RE_NONALNUM.sub('', string).lower()\n",
    "\n",
    "    def ratio(x, y):\n",
    "        if y != 0:\n",
    "            return x / float(y)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    # feature container\n",
    "    f_dict = defaultdict(dict)\n",
    "    \n",
    "    # get text features\n",
    "    body = datum['BodyMarkdown']\n",
    "    lines = body.splitlines()\n",
    "    code = []\n",
    "    text = []\n",
    "    sents = []\n",
    "    title = datum['Title']\n",
    "    tags = [norm_tag(datum[\"Tag%d\" % i])\n",
    "            for i in range(1, 6) if datum[\"Tag%d\" % i]]\n",
    "\n",
    "    # divide post into code and text blocks\n",
    "    for is_code, group in groupby(lines, lambda l: l.startswith('    ')):\n",
    "        (code if is_code else text).append('\\n'.join(group))\n",
    "\n",
    "    # build text f_dict features\n",
    "    f_dict['num']['sent'] = 0\n",
    "    f_dict['num']['question'] = 0\n",
    "    f_dict['num']['exclam'] = 0\n",
    "    f_dict['num']['period'] = 0\n",
    "    f_dict['num']['initcap'] = 0\n",
    "    f_dict['num']['istart'] = 0\n",
    "    f_dict['num']['url'] = 0\n",
    "    f_dict['num']['digit'] = 0\n",
    "    f_dict['num']['nonword'] = 0\n",
    "\n",
    "    for t in text:\n",
    "        for sent in nltk.sent_tokenize(t):\n",
    "            f_dict['num']['sent'] += 1\n",
    "            ss = sent.strip()\n",
    "            if ss:\n",
    "                if ss.endswith('?'):\n",
    "                    f_dict['num']['question'] += 1\n",
    "                if ss.endswith('!'):\n",
    "                    f_dict['num']['exclam'] += 1\n",
    "                if ss.endswith('.'):\n",
    "                    f_dict['num']['period'] += 1\n",
    "                if ss.startswith('I '):\n",
    "                    f_dict['num']['istart'] += 1\n",
    "                if ss[0].isupper():\n",
    "                    f_dict['num']['initcap'] += 1\n",
    "\n",
    "            words = nltk.word_tokenize(norm(sent))\n",
    "            sents.append(ss)\n",
    "\n",
    "        f_dict['num']['digit'] += len(RE_DIGIT.findall(t))\n",
    "        f_dict['num']['url'] += len(RE_URL.findall(t))\n",
    "        f_dict['num']['nonword'] += len(RE_NONWORD.findall(t))\n",
    "\n",
    "    f_dict['num']['finalthanks'] = 1 if text and 'thank' in text[-1].lower() else 0\n",
    "    f_dict['num']['codeblock'] = len(code)\n",
    "    f_dict['num']['textblock'] = len(text)\n",
    "    f_dict['num']['lines'] = len(lines)\n",
    "    f_dict['num']['tags'] = len(tags)\n",
    "    \n",
    "    # len features\n",
    "    f_dict['len']['title'] = len(title)\n",
    "    f_dict['len']['text'] = sum(len(t) for t in text)\n",
    "    f_dict['len']['code'] = sum(len(c) for c in code)\n",
    "    f_dict['len']['firsttext'] = len(text[0]) if text else 0\n",
    "    f_dict['len']['firstcode'] = len(code[0]) if code else 0\n",
    "    f_dict['len']['lasttext'] = len(text[-1]) if text else 0\n",
    "    f_dict['len']['lastcode'] = len(code[-1]) if code else 0\n",
    "    \n",
    "    # ratio features\n",
    "    f_dict['ratio']['tc'] = ratio(f_dict['len']['text'],\n",
    "                                  f_dict['len']['code'])\n",
    "    f_dict['ratio']['ftc'] = ratio(f_dict['len']['firsttext'],\n",
    "                                   f_dict['len']['firstcode'])\n",
    "    f_dict['ratio']['ftext'] = ratio(f_dict['len']['firsttext'],\n",
    "                                     f_dict['len']['text'])\n",
    "    f_dict['ratio']['fcode'] = ratio(f_dict['len']['firstcode'],\n",
    "                                     f_dict['len']['code'])\n",
    "    f_dict['ratio']['qsent'] = ratio(f_dict['num']['question'],\n",
    "                                     f_dict['num']['sent'])\n",
    "    f_dict['ratio']['esent'] = ratio(f_dict['num']['exclam'],\n",
    "                                     f_dict['num']['sent'])\n",
    "    f_dict['ratio']['psent'] = ratio(f_dict['num']['period'],\n",
    "                                     f_dict['num']['sent'])\n",
    "    \n",
    "    # mean features\n",
    "    f_dict['mean']['code'] = np.mean([len(c) for c in code]) if code else 0\n",
    "    f_dict['mean']['text'] = np.mean([len(t) for t in text]) if text else 0\n",
    "    f_dict['mean']['sent'] = np.mean([len(s) for s in sents]) if sents else 0\n",
    "    \n",
    "    # user's post feature \n",
    "    f_dict['user'] = dict()\n",
    "    post_time = dateparser.parse(datum['PostCreationDate'])\n",
    "    user_create_time = dateparser.parse(datum['OwnerCreationDate'])\n",
    "    f_dict['user']['age'] = (post_time - user_create_time).total_seconds()\n",
    "    f_dict['user']['reputation'] = int(datum['ReputationAtPostCreation'])\n",
    "    f_dict['user']['good_posts'] = int(datum['OwnerUndeletedAnswerCountAtPostTime'])\n",
    "\n",
    "    return f_dict\n",
    "\n",
    "def gen_datum_label(datum):\n",
    "    try:\n",
    "        post_status_id = status_map_label[datum['OpenStatus']]\n",
    "    except KeyError:\n",
    "        post_status_id = '0' # test set\n",
    "    return post_status_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a sample datum\n",
    "count = 0\n",
    "reader = csv.DictReader(open(os.path.join(data_path, 'train-sample.csv')))\n",
    "\n",
    "open_statuses = set()\n",
    "for datum in reader:\n",
    "    open_statuses.add(datum['OpenStatus'])\n",
    "    count += 1\n",
    "    if count == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_dict = gen_datum_feature_dict(datum)\n",
    "label = gen_datum_label(datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'len': {'code': 739,\n",
       "              'firstcode': 73,\n",
       "              'firsttext': 120,\n",
       "              'lastcode': 98,\n",
       "              'lasttext': 32,\n",
       "              'text': 175,\n",
       "              'title': 54},\n",
       "             'mean': {'code': 147.80000000000001,\n",
       "              'sent': 33.399999999999999,\n",
       "              'text': 29.166666666666668},\n",
       "             'num': {'codeblock': 5,\n",
       "              'digit': 0,\n",
       "              'exclam': 0,\n",
       "              'finalthanks': 1,\n",
       "              'initcap': 4,\n",
       "              'istart': 0,\n",
       "              'lines': 34,\n",
       "              'nonword': 6,\n",
       "              'period': 1,\n",
       "              'question': 0,\n",
       "              'sent': 5,\n",
       "              'tags': 3,\n",
       "              'textblock': 6,\n",
       "              'url': 0},\n",
       "             'ratio': {'esent': 0.0,\n",
       "              'fcode': 0.09878213802435724,\n",
       "              'ftc': 1.643835616438356,\n",
       "              'ftext': 0.6857142857142857,\n",
       "              'psent': 0.2,\n",
       "              'qsent': 0.0,\n",
       "              'tc': 0.2368064952638701},\n",
       "             'user': {'age': 10547952.0, 'good_posts': 24, 'reputation': 192}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
