{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "\n",
    "data_path = os.path.join(os.path.expanduser(\"~\"), 'data/stack_overflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(f):\n",
    "    for l in open(f):\n",
    "        yield l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all possible open_status\n",
    "# {'not a real question',\n",
    "#  'not constructive',\n",
    "#  'off topic',\n",
    "#  'open',\n",
    "#  'too localized'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# regexs\n",
    "RE_NONALNUM = re.compile(r'\\W+')\n",
    "RE_NONANS = re.compile(r'[^\\w\\s]+')\n",
    "RE_DIGIT = re.compile(r'\\d+')\n",
    "RE_URL = re.compile(r'https?://')\n",
    "RE_NONWORD = re.compile(r'[A-Z\\d]+')\n",
    "\n",
    "# labels from 0 to 5, 0 for undefined\n",
    "all_status = ['not a real question', \n",
    "              'not constructive',\n",
    "              'off topic', \n",
    "              'open', \n",
    "              'too localized']\n",
    "status_map_label = dict((k, str(i + 1)) for i, k in enumerate(all_status))\n",
    "\n",
    "\n",
    "def gen_datum_feature_dict(datum):\n",
    "    def norm(string):\n",
    "        return RE_NONANS.sub('', string).lower()\n",
    "\n",
    "    def norm_tag(string):\n",
    "        return RE_NONALNUM.sub('', string).lower()\n",
    "\n",
    "    def ratio(x, y):\n",
    "        if y != 0:\n",
    "            return x / float(y)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    # feature containers\n",
    "    f_dict = defaultdict(dict)\n",
    "    user = dict()\n",
    "\n",
    "    # get text feature\n",
    "    body = datum['BodyMarkdown']\n",
    "    lines = body.splitlines()\n",
    "    code = []\n",
    "    text = []\n",
    "    sents = []\n",
    "\n",
    "    # divide post into code and text blocks\n",
    "    for is_code, group in groupby(lines, lambda l: l.startswith('    ')):\n",
    "        (code if is_code else text).append('\\n'.join(group))\n",
    "\n",
    "    # build text f_dict features\n",
    "    f_dict['num']['sent'] = 0\n",
    "    f_dict['num']['question'] = 0\n",
    "    f_dict['num']['exclam'] = 0\n",
    "    f_dict['num']['period'] = 0\n",
    "    f_dict['num']['initcap'] = 0\n",
    "    f_dict['num']['istart'] = 0\n",
    "    f_dict['num']['url'] = 0\n",
    "    f_dict['num']['digit'] = 0\n",
    "    f_dict['num']['nonword'] = 0\n",
    "\n",
    "    for t in text:\n",
    "        for sent in nltk.sent_tokenize(t):\n",
    "            f_dict['num']['sent'] += 1\n",
    "            ss = sent.strip()\n",
    "            if ss:\n",
    "                if ss.endswith('?'):\n",
    "                    f_dict['num']['question'] += 1\n",
    "                if ss.endswith('!'):\n",
    "                    f_dict['num']['exclam'] += 1\n",
    "                if ss.endswith('.'):\n",
    "                    f_dict['num']['period'] += 1\n",
    "                if ss.startswith('I '):\n",
    "                    f_dict['num']['istart'] += 1\n",
    "                if ss[0].isupper():\n",
    "                    f_dict['num']['initcap'] += 1\n",
    "\n",
    "            words = nltk.word_tokenize(norm(sent))\n",
    "            sents.append(ss)\n",
    "\n",
    "        f_dict['num']['digit'] += len(RE_DIGIT.findall(t))\n",
    "        f_dict['num']['url'] += len(RE_URL.findall(t))\n",
    "        f_dict['num']['nonword'] += len(RE_NONWORD.findall(t))\n",
    "\n",
    "    # title, tags, post_id\n",
    "    title = datum['Title']\n",
    "    tags = [norm_tag(datum[\"Tag%d\" % i])\n",
    "            for i in range(1, 6) if datum[\"Tag%d\" % i]]\n",
    "\n",
    "    # user's post feature\n",
    "    post_time = dateparser.parse(datum['PostCreationDate'])\n",
    "    user_create_time = dateparser.parse(datum['OwnerCreationDate'])\n",
    "    user['age'] = (post_time - user_create_time).total_seconds()\n",
    "    user['reputation'] = int(datum['ReputationAtPostCreation'])\n",
    "    user['good_posts'] = int(datum['OwnerUndeletedAnswerCountAtPostTime'])\n",
    "    f_dict['user'] = user\n",
    "\n",
    "    f_dict['num']['finalthanks'] = 1 if text and 'thank' in text[-1].lower() else 0\n",
    "    f_dict['num']['codeblock'] = len(code)\n",
    "    f_dict['num']['textblock'] = len(text)\n",
    "    f_dict['num']['lines'] = len(lines)\n",
    "    f_dict['num']['tags'] = len(tags)\n",
    "    f_dict['len']['title'] = len(title)\n",
    "    f_dict['len']['text'] = sum(len(t) for t in text)\n",
    "    f_dict['len']['code'] = sum(len(c) for c in code)\n",
    "    f_dict['len']['firsttext'] = len(text[0]) if text else 0\n",
    "    f_dict['len']['firstcode'] = len(code[0]) if code else 0\n",
    "    f_dict['len']['lasttext'] = len(text[-1]) if text else 0\n",
    "    f_dict['len']['lastcode'] = len(code[-1]) if code else 0\n",
    "    f_dict['ratio']['tc'] = ratio(f_dict['len']['text'],\n",
    "                                  f_dict['len']['code'])\n",
    "    f_dict['ratio']['ftc'] = ratio(f_dict['len']['firsttext'],\n",
    "                                   f_dict['len']['firstcode'])\n",
    "    f_dict['ratio']['ftext'] = ratio(f_dict['len']['firsttext'],\n",
    "                                     f_dict['len']['text'])\n",
    "    f_dict['ratio']['fcode'] = ratio(f_dict['len']['firstcode'],\n",
    "                                     f_dict['len']['code'])\n",
    "    f_dict['ratio']['qsent'] = ratio(f_dict['num']['question'],\n",
    "                                     f_dict['num']['sent'])\n",
    "    f_dict['ratio']['esent'] = ratio(f_dict['num']['exclam'],\n",
    "                                     f_dict['num']['sent'])\n",
    "    f_dict['ratio']['psent'] = ratio(f_dict['num']['period'],\n",
    "                                     f_dict['num']['sent'])\n",
    "    f_dict['mean']['code'] = np.mean([len(c) for c in code]) if code else 0\n",
    "    f_dict['mean']['text'] = np.mean([len(t) for t in text]) if text else 0\n",
    "    f_dict['mean']['sent'] = np.mean([len(s) for s in sents]) if sents else 0\n",
    "\n",
    "    return f_dict\n",
    "\n",
    "\n",
    "def gen_datum_label(datum):\n",
    "    try:\n",
    "        post_status = status_map_label[datum['OpenStatus']]\n",
    "    except KeyError:\n",
    "        post_status = '0'  # test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "reader = csv.DictReader(open(os.path.join(data_path, 'train-sample.csv')))\n",
    "\n",
    "open_statuses = set()\n",
    "for datum in reader:\n",
    "    open_statuses.add(datum['OpenStatus'])\n",
    "    count += 1\n",
    "    if count == 2:\n",
    "        break\n",
    "        \n",
    "feature_dict = gen_datum_feature_dict(datum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
