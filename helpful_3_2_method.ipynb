{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# my version of the algorithm used in the baseline\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import cPickle as pickle\n",
    "import time\n",
    "import os\n",
    "from __future__ import print_function\n",
    "\n",
    "data_root = os.path.expanduser(\"~\") + '/data/CSE255/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.0732281208\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "all_data = pickle.load(open(data_root + \"all_data.pickle\", \"rb\"))\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_size = len(all_data)\n",
    "train_size = 900000\n",
    "# train_size = all_size\n",
    "valid_size = 100000\n",
    "train_data = all_data[:train_size]\n",
    "valid_data = all_data[all_size - valid_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def get_mae(helpfuls, helpfuls_predict):\n",
    "    return np.sum(np.fabs(helpfuls_predict - helpfuls.astype(float))) / helpfuls.shape[0]\n",
    "\n",
    "def get_valid_mae(valid_data, alpha, beta_us, beta_is):\n",
    "    helpfuls = np.array([float(d['helpful']['nHelpful']) for d in valid_data])\n",
    "    helpfuls_predict = np.array([predict_helpful(d, alpha, beta_us, beta_is) for d in valid_data])\n",
    "    return get_mae(helpfuls, helpfuls_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pre-process 0: build id <-> index infastructure\n",
    "\n",
    "# get all items and users\n",
    "item_ids = sorted(list(set([d['itemID'] for d in all_data])))\n",
    "user_ids = sorted(list(set([d['reviewerID'] for d in all_data])))\n",
    "\n",
    "# user and item numbers\n",
    "num_items = len(item_ids)\n",
    "num_users = len(user_ids)\n",
    "\n",
    "# build id <-> index map\n",
    "item_id_map_index = dict()\n",
    "item_index_map_id = dict()\n",
    "for index, item_id in enumerate(item_ids):\n",
    "    item_id_map_index[item_id] = index\n",
    "    item_index_map_id[index] = item_id\n",
    "    \n",
    "user_id_map_index = dict()\n",
    "user_index_map_id = dict()\n",
    "for index, user_id in enumerate(user_ids):\n",
    "    user_id_map_index[user_id] = index\n",
    "    user_index_map_id[index] = user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre-process 1: build train_ratio_array, valid_ratio_array\n",
    "\n",
    "def get_ratio(d):\n",
    "    return float(d['helpful']['nHelpful']) / float(d['helpful']['outOf'])\n",
    "\n",
    "# build array [user_index, item_index, ratio]\n",
    "train_ratio_array = []\n",
    "for d in train_data:\n",
    "    user_index = user_id_map_index[d['reviewerID']]\n",
    "    item_index = item_id_map_index[d['itemID']]\n",
    "    if float(d['helpful']['outOf']) != 0:\n",
    "        ratio = get_ratio(d)\n",
    "        train_ratio_array.append([user_index, item_index, ratio])\n",
    "train_ratio_array = np.array(train_ratio_array)\n",
    "\n",
    "# build array [user_index, item_index, ratio]\n",
    "valid_ratio_array = []\n",
    "for d in valid_data:\n",
    "    user_index = user_id_map_index[d['reviewerID']]\n",
    "    item_index = item_id_map_index[d['itemID']]\n",
    "    if float(d['helpful']['outOf']) != 0:\n",
    "        ratio = get_ratio(d)\n",
    "        valid_ratio_array.append([user_index, item_index, ratio])\n",
    "valid_ratio_array = np.array(valid_ratio_array)\n",
    "\n",
    "# build array [user_index, item_index, ratio]\n",
    "all_ratio_array = []\n",
    "for d in all_data:\n",
    "    user_index = user_id_map_index[d['reviewerID']]\n",
    "    item_index = item_id_map_index[d['itemID']]\n",
    "    if float(d['helpful']['outOf']) != 0:\n",
    "        ratio = get_ratio(d)\n",
    "        all_ratio_array.append([user_index, item_index, ratio])\n",
    "all_ratio_array = np.array(all_ratio_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility and update functions\n",
    "\n",
    "def get_valid_mse(lam, alpha, beta_us, beta_is, ratio_array, valid_ratio_array):\n",
    "    predicts = alpha + beta_us[valid_ratio_array[:, 0].astype(int)] + beta_is[valid_ratio_array[:, 1].astype(int)]\n",
    "    ratios = valid_ratio_array[:, 2].astype(float)\n",
    "    return (1. / valid_ratio_array.shape[0]) * np.sum((predicts - ratios) ** 2.0)\n",
    "\n",
    "def get_cost(lam, alpha, beta_us, beta_is, train_ratio_array, Ruis, Rius):\n",
    "    predicts = alpha + beta_us[train_ratio_array[:, 0].astype(int)] + beta_is[train_ratio_array[:, 1].astype(int)]\n",
    "    ratios = train_ratio_array[:, 2].astype(float)\n",
    "    return np.sum((predicts - ratios) ** 2.) + lam * (np.sum(beta_us ** 2.) + np.sum(beta_is ** 2.))\n",
    "\n",
    "def alpha_update(lam, alpha, beta_us, beta_is, train_ratio_array, Ruis, Rius):\n",
    "    sum_Rui = np.sum(train_ratio_array[:, 2])\n",
    "    sum_beta_u = np.sum(beta_us[train_ratio_array[:, 0].astype(int)]) # fancy indexing\n",
    "    sum_beta_i = np.sum(beta_is[train_ratio_array[:, 1].astype(int)]) # fancy indexing\n",
    "    return (sum_Rui - sum_beta_u - sum_beta_i) / train_ratio_array.shape[0]\n",
    "\n",
    "def beta_us_update(lam, alpha, beta_us, beta_is, train_ratio_array, Ruis, Rius):\n",
    "    new_beta_us = np.zeros_like(beta_us)\n",
    "    for user_index in xrange(num_users):\n",
    "        # [the set of items] reviewed by user u\n",
    "        Iu = Ruis[user_index].keys()\n",
    "        Iu_size = len(Iu)\n",
    "        # sums\n",
    "        sum_Rui = np.sum(Ruis[user_index].values())\n",
    "        sum_alpha = Iu_size * alpha\n",
    "        sum_beta_i = np.sum(beta_is[Iu])\n",
    "        # write result\n",
    "        new_beta_us[user_index] = float(sum_Rui - sum_alpha - sum_beta_i) / (lam + Iu_size)\n",
    "    return new_beta_us\n",
    "\n",
    "def beta_is_update(lam, alpha, beta_us, beta_is, train_ratio_array, Ruis, Rius):\n",
    "    new_beta_is = np.zeros_like(beta_is)\n",
    "    for item_index in xrange(num_items):\n",
    "        # [the set of users] reviewd item i\n",
    "        Ui = Rius[item_index].keys()\n",
    "        Ui_size = len(Ui)\n",
    "        # sums\n",
    "        sum_Rui = np.sum(Rius[item_index].values())\n",
    "        sum_alpha = Ui_size * alpha\n",
    "        sum_beta_u = np.sum(beta_us[Ui])\n",
    "        # write result\n",
    "        new_beta_is[item_index] = float(sum_Rui - sum_alpha - sum_beta_u) / (lam + Ui_size)\n",
    "    return new_beta_is\n",
    "\n",
    "def train_and_eval(max_iter,\n",
    "                   lam, alpha, beta_us, beta_is,\n",
    "                   train_ratio_array, valid_ratio_array, valid_data,\n",
    "                   print_step = False):\n",
    "\n",
    "    # build Mapping of Ruis and Rius\n",
    "    Ruis = defaultdict(dict)\n",
    "    Rius = defaultdict(dict)\n",
    "\n",
    "    # Notes:\n",
    "    # Iu = Ruis[user_index].keys() # [the set of items] reviewed by user u\n",
    "    # Ui = Ruis[item_index].keys() # [the set of users] reviewed item i\n",
    "\n",
    "    for t in train_ratio_array:\n",
    "        user_index = t[0]\n",
    "        item_index = t[1]\n",
    "        ratio = t[2]\n",
    "        Ruis[user_index][item_index] = ratio\n",
    "        Rius[item_index][user_index] = ratio\n",
    "\n",
    "    # train on this dataset\n",
    "    for i in xrange(max_iter):\n",
    "        alpha = alpha_update(lam, alpha, beta_us, beta_is, train_ratio_array, Ruis, Rius)\n",
    "        beta_us = beta_us_update(lam, alpha, beta_us, beta_is, train_ratio_array, Ruis, Rius)\n",
    "        beta_is = beta_is_update(lam, alpha, beta_us, beta_is, train_ratio_array, Ruis, Rius)\n",
    "        if print_step:\n",
    "            cost = get_cost(lam, alpha, beta_us, beta_is, train_ratio_array, Ruis, Rius)\n",
    "            valid_mse = get_valid_mse(lam, alpha, beta_us, beta_is,\n",
    "                                      train_ratio_array, valid_ratio_array)\n",
    "            valid_mae = get_valid_mae(valid_data, alpha, beta_us, beta_is)\n",
    "            print(i, alpha, np.mean(beta_us), np.mean(beta_is), cost, valid_mse, valid_mae)\n",
    "\n",
    "    cost = get_cost(lam, alpha, beta_us, beta_is, train_ratio_array, Ruis, Rius)\n",
    "    valid_mse = get_valid_mse(lam, alpha, beta_us, beta_is, train_ratio_array, valid_ratio_array)\n",
    "\n",
    "    return(cost, valid_mse, alpha, beta_us, beta_is)\n",
    "\n",
    "def predict_helpful(d, alpha, beta_us, beta_is):\n",
    "    user_id = d['reviewerID']\n",
    "    item_id = d['itemID']\n",
    "    outof = float(d['helpful']['outOf'])\n",
    "    ratio = alpha + beta_us[user_id_map_index[user_id]] + beta_is[item_id_map_index[item_id]]\n",
    "    ratio = min(5.0, ratio)\n",
    "    ratio = max(0.0, ratio)\n",
    "    helpful_predict = ratio * outof\n",
    "    \n",
    "    return helpful_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.745353848972 -0.0145881555102 0.00875687477617 41840.9328846 0.112306128071 0.774115423878\n",
      "1 0.746048669228 -0.0127770609623 0.00956923584893 34552.2232366 0.0939125888091 0.685657955272\n",
      "2 0.746807946832 -0.0131928454579 0.00886756892515 34361.9194486 0.0934033256027 0.682451768427\n",
      "3 0.747511550192 -0.0135522725803 0.00778264668251 34333.7012457 0.0933302383421 0.681402556252\n",
      "4 0.748129069649 -0.0136255763937 0.00660757437299 34321.3906151 0.0932982836038 0.680710114535\n",
      "5 0.748653352185 -0.0134611448797 0.00544412285244 34314.1388249 0.0932792186206 0.680201546818\n",
      "6 0.74908531986 -0.0131324403296 0.00433532949666 34309.4183305 0.093266674903 0.679814341853\n",
      "7 0.749429309563 -0.0126979240306 0.00330104253613 34306.1816021 0.093257941424 0.679507871883\n",
      "8 0.749691233054 -0.0121990507425 0.00234994071764 34303.8831614 0.0932515763703 0.679259004656\n",
      "9 0.749877690718 -0.0116643334393 0.00148461141377 34302.2056658 0.0932467447065 0.679053844586\n",
      "10 0.749995488232 -0.0111132631518 0.000704113609283 34300.9524671 0.0932429418899 0.678884202085\n",
      "11 0.750051356611 -0.0105591687 5.43063354182e-06 34299.9966383 0.0932398543002 0.678741464596\n",
      "12 0.750051787508 -0.0100111593148 -0.000615649553452 34299.2537451 0.0932372821052 0.678620131109\n",
      "13 0.750002938371 -0.00947542271728 -0.00116398125704 34298.6661961 0.0932350947167 0.678516397341\n",
      "14 0.749910581476 -0.00895609674447 -0.00164470709939 34298.1938275 0.0932332044412 0.67842740208\n",
      "15 0.749780081059 -0.00845586299862 -0.00206303007269 34297.8080634 0.0932315506419 0.678351010687\n",
      "16 0.749616388518 -0.00797635843772 -0.00242406733446 34297.4882078 0.0932300900891 0.678285138786\n",
      "17 0.749424049227 -0.00751846597592 -0.00273275795716 34297.2190393 0.093228790999 0.678228228267\n",
      "18 0.749207216666 -0.00708252310439 -0.00299380672908 34296.9892199 0.0932276292959 0.678178957444\n",
      "19 0.74896967101 -0.00666847378771 -0.00321165224171 34296.7902183 0.0932265862293 0.678136307479\n",
      "20 0.748714840253 -0.00627598030102 -0.00339045140628 34296.6155665 0.0932256468246 0.678099415102\n",
      "21 0.748445822552 -0.00590450624872 -0.00353407507797 34296.4603344 0.0932247988563 0.678067553116\n",
      "22 0.748165408933 -0.00555337852015 -0.00364611114136 34296.3207513 0.0932240321511 0.678040086874\n",
      "23 0.747876105734 -0.00522183364965 -0.00372987253312 34296.193928 0.0932233381053 0.678016476692\n",
      "24 0.747580156431 -0.00490905251075 -0.00378840844126 34296.0776489 0.093222709342 0.677996264036\n",
      "25 0.747279562556 -0.00461418621709 -0.00382451744653 34295.9702152 0.0932221394623 0.677979061599\n",
      "26 0.746976103587 -0.00433637535833 -0.00384076173828 34295.8703237 0.0932216228618 0.677964528864\n",
      "27 0.746671355703 -0.00407476416625 -0.00383948179529 34295.7769752 0.0932211545906 0.677952323429\n",
      "28 0.746366709377 -0.00382851081624 -0.00382281110647 34295.6894018 0.0932207302469 0.677942179689\n",
      "29 0.746063385799 -0.00359679478149 -0.00379269063762 34295.6070118 0.0932203458927 0.677933857473\n"
     ]
    }
   ],
   "source": [
    "# fit linear model: ratio(u, i) = alpha + beta_u + beta_i\n",
    "\n",
    "# parameters\n",
    "max_iter = 30\n",
    "lam = 1.0\n",
    "alpha = 0.7704\n",
    "beta_us = np.random.normal(0, 0.5, (num_users,))\n",
    "beta_is = np.random.normal(0, 0.5, (num_items,))\n",
    "\n",
    "cost, valid_mse, alpha, beta_us, beta_is = train_and_eval(max_iter, \n",
    "                                                          lam, alpha, beta_us, beta_is, \n",
    "                                                          train_ratio_array, valid_ratio_array, valid_data,\n",
    "                                                          print_step=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6779338574730378"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_valid_mae(valid_data, alpha, beta_us, beta_is)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
