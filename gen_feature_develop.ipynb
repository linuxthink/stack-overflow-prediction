{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "from itertools import groupby\n",
    "import nltk\n",
    "from dateutil import parser as dateparser\n",
    "from pprint import pprint\n",
    "\n",
    "data_path = os.path.join(os.path.expanduser(\"~\"), 'data/stack_overflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: package into class\n",
    "def norm(string):\n",
    "    return RE_NONANS.sub('', string).lower()\n",
    "\n",
    "def norm_tag(string):\n",
    "    return RE_NONALNUM.sub('', string).lower()\n",
    "\n",
    "def ratio(x, y):\n",
    "    if y != 0:\n",
    "        return x / float(y)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def dict_to_list(d):\n",
    "    stack = []\n",
    "    keys = sorted(d.keys())\n",
    "    for k in keys:\n",
    "        if type(d[k]) in (dict, defaultdict):\n",
    "            stack += dict_to_list(d[k])\n",
    "        else:\n",
    "            stack.append(d[k])\n",
    "    return stack\n",
    "\n",
    "def dict_to_keys(d, prefix=''):\n",
    "    stack = []\n",
    "    keys = sorted(d.keys())\n",
    "    for k in keys:\n",
    "        prefix_k = k if len(prefix) == 0 else prefix + '-' + k\n",
    "        if type(d[k]) in (dict, defaultdict):\n",
    "            stack += dict_to_keys(d[k], prefix_k)\n",
    "        else:\n",
    "            stack.append(prefix_k)\n",
    "    return stack\n",
    "    \n",
    "# regexs\n",
    "RE_NONALNUM = re.compile(r'\\W+')\n",
    "RE_NONANS = re.compile(r'[^\\w\\s]+')\n",
    "RE_DIGIT = re.compile(r'\\d+')\n",
    "RE_URL = re.compile(r'https?://')\n",
    "RE_NONWORD = re.compile(r'[A-Z\\d]+')\n",
    "\n",
    "# labels from 0 to 5, 0 for undefined\n",
    "all_status = ['not a real question', # 1\n",
    "              'not constructive',    # 2\n",
    "              'off topic',           # 3\n",
    "              'open',                # 4\n",
    "              'too localized']       # 5\n",
    "status_map_label = dict((k, int(i + 1)) for i, k in enumerate(all_status))\n",
    "\n",
    "\n",
    "class FeatureLabelBuilder(object):\n",
    "    \"\"\"\n",
    "    Usage:\n",
    "        flb = FeatureLabelBuilder(datum)\n",
    "        # usually\n",
    "        flb.feature\n",
    "        flb.label\n",
    "        # can return feature as dict\n",
    "        flb.feature_dict\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, datum):\n",
    "        self.datum = datum\n",
    "        self.feature_nested_dict = FeatureLabelBuilder.__get_feature_nested_dict(self.datum)\n",
    "        self.label = FeatureLabelBuilder.__get_label(self.datum)\n",
    "        self.feature = dict_to_list(self.feature_nested_dict)\n",
    "        self.feature_keys_cache = None # to be computed on demand\n",
    "        self.feature_dict_cache = None # to be computed on demand\n",
    "        \n",
    "    @property\n",
    "    def feature_keys(self):\n",
    "        if not self.feature_keys_cache:\n",
    "            self.feature_keys_cache = dict_to_keys(self.feature_nested_dict)\n",
    "        return self.feature_keys_cache\n",
    "\n",
    "    @property\n",
    "    def feature_dict(self):\n",
    "        if not self.feature_dict_cache:\n",
    "            d = dict()\n",
    "            keys = self.feature_keys\n",
    "            vals = self.feature\n",
    "            for k, v in zip(keys, vals):\n",
    "                d[k] = v\n",
    "            self.feature_dict_cache = d\n",
    "        return self.feature_dict_cache\n",
    "    \n",
    "    @staticmethod\n",
    "    def __get_feature_nested_dict(datum):\n",
    "        \"\"\"\n",
    "        return feature in a dict format\n",
    "        \"\"\"\n",
    "\n",
    "        # feature container\n",
    "        f_dict = defaultdict(dict)\n",
    "\n",
    "        # get text features\n",
    "        body = datum['BodyMarkdown']\n",
    "        lines = body.splitlines()\n",
    "        code = [] # code\n",
    "        text = [] # text\n",
    "        sentences = [] # sentence\n",
    "        title = datum['Title'] # title\n",
    "        tags = [norm_tag(datum[\"Tag%d\" % i])\n",
    "                for i in range(1, 6) if datum[\"Tag%d\" % i]]\n",
    "\n",
    "        # divide post into code and text blocks\n",
    "        for is_code, group in groupby(lines, lambda l: l.startswith('    ')):\n",
    "            (code if is_code else text).append('\\n'.join(group))\n",
    "\n",
    "        # build text f_dict features\n",
    "        f_dict['num']['sentence'] = 0\n",
    "        f_dict['num']['question'] = 0\n",
    "        f_dict['num']['exclam'] = 0\n",
    "        f_dict['num']['period'] = 0\n",
    "        f_dict['num']['init_cap'] = 0\n",
    "        f_dict['num']['i_start'] = 0\n",
    "        f_dict['num']['url'] = 0\n",
    "        f_dict['num']['digit'] = 0\n",
    "        f_dict['num']['non_word'] = 0\n",
    "\n",
    "        for t in text:\n",
    "            for sent in nltk.sent_tokenize(t):\n",
    "                f_dict['num']['sentence'] += 1\n",
    "                ss = sent.strip()\n",
    "                if ss:\n",
    "                    if ss.endswith('?'):\n",
    "                        f_dict['num']['question'] += 1\n",
    "                    if ss.endswith('!'):\n",
    "                        f_dict['num']['exclam'] += 1\n",
    "                    if ss.endswith('.'):\n",
    "                        f_dict['num']['period'] += 1\n",
    "                    if ss.startswith('I '):\n",
    "                        f_dict['num']['i_start'] += 1\n",
    "                    if ss[0].isupper():\n",
    "                        f_dict['num']['init_cap'] += 1\n",
    "\n",
    "                words = nltk.word_tokenize(norm(sent))\n",
    "                sentences.append(ss)\n",
    "\n",
    "            f_dict['num']['digit'] += len(RE_DIGIT.findall(t))\n",
    "            f_dict['num']['url'] += len(RE_URL.findall(t))\n",
    "            f_dict['num']['non_word'] += len(RE_NONWORD.findall(t))\n",
    "\n",
    "        f_dict['num']['final_thanks'] = 1 if text and 'thank' in text[-1].lower() else 0\n",
    "        f_dict['num']['code_block'] = len(code)\n",
    "        f_dict['num']['text_block'] = len(text)\n",
    "        f_dict['num']['lines'] = len(lines)\n",
    "        f_dict['num']['tags'] = len(tags)\n",
    "\n",
    "        # len features\n",
    "        f_dict['len']['title'] = len(title)\n",
    "        f_dict['len']['text'] = sum(len(t) for t in text)\n",
    "        f_dict['len']['code'] = sum(len(c) for c in code)\n",
    "        f_dict['len']['first_text'] = len(text[0]) if text else 0\n",
    "        f_dict['len']['first_code'] = len(code[0]) if code else 0\n",
    "        f_dict['len']['last_text'] = len(text[-1]) if text else 0\n",
    "        f_dict['len']['last_code'] = len(code[-1]) if code else 0\n",
    "\n",
    "        # ratio features\n",
    "        f_dict['ratio']['text_code'] = ratio(f_dict['len']['text'],\n",
    "                                      f_dict['len']['code'])\n",
    "        f_dict['ratio']['first_text_first_code'] = ratio(f_dict['len']['first_text'],\n",
    "                                                         f_dict['len']['first_code'])\n",
    "        f_dict['ratio']['first_text_text'] = ratio(f_dict['len']['first_text'],\n",
    "                                                   f_dict['len']['text'])\n",
    "        f_dict['ratio']['first_code_code'] = ratio(f_dict['len']['first_code'],\n",
    "                                                   f_dict['len']['code'])\n",
    "        f_dict['ratio']['question_sentence'] = ratio(f_dict['num']['question'],\n",
    "                                                     f_dict['num']['sentence'])\n",
    "        f_dict['ratio']['exclam_sentence'] = ratio(f_dict['num']['exclam'],\n",
    "                                                   f_dict['num']['sentence'])\n",
    "        f_dict['ratio']['period_sentence'] = ratio(f_dict['num']['period'],\n",
    "                                                   f_dict['num']['sentence'])\n",
    "\n",
    "        # mean features\n",
    "        f_dict['mean']['code'] = np.mean([len(c) for c in code]) if code else 0\n",
    "        f_dict['mean']['text'] = np.mean([len(t) for t in text]) if text else 0\n",
    "        f_dict['mean']['sentence'] = np.mean(\n",
    "            [len(s) for s in sentences]) if sentences else 0\n",
    "\n",
    "        # user's post feature\n",
    "        f_dict['user'] = dict()\n",
    "        post_time = dateparser.parse(datum['PostCreationDate'])\n",
    "        user_create_time = dateparser.parse(datum['OwnerCreationDate'])\n",
    "        f_dict['user']['age'] = (post_time - user_create_time).total_seconds()\n",
    "        f_dict['user']['reputation'] = int(datum['ReputationAtPostCreation'])\n",
    "        f_dict['user']['good_posts'] = int(\n",
    "            datum['OwnerUndeletedAnswerCountAtPostTime'])\n",
    "\n",
    "        # time\n",
    "        f_dict['time']['year'] = post_time.year\n",
    "        f_dict['time']['month'] = post_time.month\n",
    "        f_dict['time']['day'] = post_time.day\n",
    "        f_dict['time']['weekday'] = post_time.weekday()\n",
    "\n",
    "        return dict(f_dict)\n",
    "    \n",
    "    @staticmethod\n",
    "    def __get_label(datum):\n",
    "        \"\"\"\n",
    "        return label as int 0,1,2,3,4,5; 0 if test set\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            label = status_map_label[datum['OpenStatus']]\n",
    "        except KeyError:\n",
    "            label = 0  # test set\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BodyMarkdown': 'I want to write a client for a site on windows phone 7 but the site has no API. The client should simply take data from a website and display of a suitable form. What can I use to write such a client',\n",
      " 'OpenStatus': 'not a real question',\n",
      " 'OwnerCreationDate': '12/22/2011 12:58:55',\n",
      " 'OwnerUndeletedAnswerCountAtPostTime': '0',\n",
      " 'OwnerUserId': '1111755',\n",
      " 'PostClosedDate': '12/22/2011 14:22:55',\n",
      " 'PostCreationDate': '12/22/2011 13:43:33',\n",
      " 'PostId': '8604738',\n",
      " 'ReputationAtPostCreation': '1',\n",
      " 'Tag1': 'c#',\n",
      " 'Tag2': 'windows-phone-7',\n",
      " 'Tag3': '',\n",
      " 'Tag4': '',\n",
      " 'Tag5': '',\n",
      " 'Title': 'Windows Phone client for site'}\n"
     ]
    }
   ],
   "source": [
    "# get a sample datum\n",
    "reader = csv.DictReader(open(os.path.join(data_path, 'train-sample.csv')))\n",
    "\n",
    "count = 0\n",
    "for datum in reader:\n",
    "    count += 1\n",
    "    if count == 1123:\n",
    "        break\n",
    "        \n",
    "# print datum\n",
    "pprint(datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'len-code': 0,\n",
       " 'len-first_code': 0,\n",
       " 'len-first_text': 199,\n",
       " 'len-last_code': 0,\n",
       " 'len-last_text': 199,\n",
       " 'len-text': 199,\n",
       " 'len-title': 29,\n",
       " 'mean-code': 0,\n",
       " 'mean-sentence': 65.666666666666671,\n",
       " 'mean-text': 199.0,\n",
       " 'num-code_block': 0,\n",
       " 'num-digit': 1,\n",
       " 'num-exclam': 0,\n",
       " 'num-final_thanks': 0,\n",
       " 'num-i_start': 1,\n",
       " 'num-init_cap': 3,\n",
       " 'num-lines': 1,\n",
       " 'num-non_word': 6,\n",
       " 'num-period': 2,\n",
       " 'num-question': 0,\n",
       " 'num-sentence': 3,\n",
       " 'num-tags': 2,\n",
       " 'num-text_block': 1,\n",
       " 'num-url': 0,\n",
       " 'ratio-exclam_sentence': 0.0,\n",
       " 'ratio-first_code_code': 0,\n",
       " 'ratio-first_text_first_code': 0,\n",
       " 'ratio-first_text_text': 1.0,\n",
       " 'ratio-period_sentence': 0.6666666666666666,\n",
       " 'ratio-question_sentence': 0.0,\n",
       " 'ratio-text_code': 0,\n",
       " 'time-day': 22,\n",
       " 'time-month': 12,\n",
       " 'time-weekday': 3,\n",
       " 'time-year': 2011,\n",
       " 'user-age': 2678.0,\n",
       " 'user-good_posts': 0,\n",
       " 'user-reputation': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flb = FeatureLabelBuilder(datum)\n",
    "flb.feature_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
