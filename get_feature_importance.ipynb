{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from pprint import pprint\n",
    "import os\n",
    "import csv\n",
    "import cPickle as pickle\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "\n",
    "from feature_label_builder import FeatureLabelBuilder\n",
    "data_path = os.path.join(os.path.expanduser(\"~\"), 'data/stack_overflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_feature_keys():\n",
    "    reader = csv.DictReader(open(os.path.join(data_path, 'train-sample.csv')))\n",
    "\n",
    "    count = 0\n",
    "    for datum in reader:\n",
    "        count += 1\n",
    "        if count == 2:\n",
    "            break\n",
    "\n",
    "    flb = FeatureLabelBuilder(datum)\n",
    "    return flb.feature_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reader = csv.DictReader(open(os.path.join(data_path, 'train-sample.csv')))\n",
    "\n",
    "# train_xs = []\n",
    "# train_ys = []\n",
    "\n",
    "# count = 0\n",
    "# for datum in reader:\n",
    "#     if count % 1000 == 0:\n",
    "#         print(count)\n",
    "#     count += 1\n",
    "#     flb = FeatureLabelBuilder(datum)\n",
    "#     train_xs.append(flb.feature)\n",
    "#     train_ys.append(flb.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle.dump((train_xs, train_ys), open(\"train_xs_ys.p\", \"wb\"), \n",
    "#             protocol=pickle.HIGHEST_PROTOCOL)\n",
    "(train_xs, train_ys) = pickle.load(open(\"train_xs_ys.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       80194.1966        5463.2032           67.24m\n",
      "         2       77388.1387        4287.1330           66.96m\n",
      "         3       74923.3923        3421.9392           66.79m\n",
      "         4       73111.7875        2831.2371           66.72m\n",
      "         5       71500.1618        2311.6220           66.63m\n",
      "         6       70306.6508        1899.0545           66.50m\n",
      "         7       69171.9305        1632.1451           66.45m\n",
      "         8       68218.7895        1364.4907           66.40m\n",
      "         9       67438.0389        1131.4256           66.33m\n",
      "        10       67000.0076         979.6289           66.23m\n",
      "        20       63090.4105         286.7779           65.77m\n",
      "        30       61967.6306         111.6336           65.02m\n",
      "        40       61312.4663          61.1167           64.23m\n",
      "        50       60883.1884          34.6414           63.50m\n",
      "        60       60607.1453          16.4543           62.78m\n",
      "        70       60283.3559           5.7872           62.05m\n",
      "        80       60694.0857           7.2736           61.35m\n",
      "        90       60386.7396          -5.1944           60.65m\n",
      "       100       60087.5292          -1.7002           59.98m\n",
      "       200       59273.5706          -4.9179           52.65m\n",
      "       300       58842.5423          -5.5590           45.73m\n",
      "       400       58229.3631          -4.5426           39.09m\n",
      "       500       57672.4764          -5.2496           32.51m\n",
      "       600       57239.6339          -7.4159           25.98m\n",
      "       700       56632.4203          -4.3224           19.46m\n",
      "       800       65205.3112          -7.1150           12.96m\n",
      "       900       55902.8603         -11.6472            6.48m\n",
      "      1000       65610.3759          -8.5365            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "              presort='auto', random_state=None, subsample=0.4, verbose=1,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = GBC(n_estimators=1000,\n",
    "                 learning_rate=0.1,\n",
    "                 subsample=0.4,\n",
    "                 max_features='auto',\n",
    "                 verbose=1)\n",
    "classifier.fit(train_xs, train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys = get_feature_keys()\n",
    "f = open('feature_importance.txt', 'w')\n",
    "for key, val in zip(keys, classifier.feature_importances_):\n",
    "    print(key, val, file=f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
